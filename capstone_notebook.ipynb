{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: AI Data Quality Checker\n",
    "### Version: 1.0\n",
    "### Created by: Omar Chehab\n",
    "### Date: 30-11-2025\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Key Features Demonstrated in This Project\n",
    "\n",
    "This project showcases **4 key concepts** from the AI Agents course:\n",
    "\n",
    "| # | Feature | Implementation |\n",
    "|---|---------|----------------|\n",
    "| 1 | **LLM-Powered Agent** | `AnalyticsAgent` class using Google Gemini for intelligent Q&A |\n",
    "| 2 | **Custom Tools** | Analysis methods (geography, demographics, financial profiling) |\n",
    "| 3 | **Sessions & Memory** | `SessionManager` with `InMemorySessionService` and long-term `MemoryBank` |\n",
    "| 4 | **Observability** | `AgentObservability` class with logging, tracing, and metrics |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Importing Required Modules\n",
    "\n",
    "Import all necessary libraries including:\n",
    "- **Google ADK** - Agent Development Kit for building AI agents\n",
    "- **pandas** - Data manipulation and analysis\n",
    "- **logging** - For observability and debugging\n",
    "- **datetime/time** - For session management and metrics tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T19:13:22.800788Z",
     "iopub.status.busy": "2025-11-30T19:13:22.800459Z",
     "iopub.status.idle": "2025-11-30T19:13:22.807687Z",
     "shell.execute_reply": "2025-11-30T19:13:22.806593Z",
     "shell.execute_reply.started": "2025-11-30T19:13:22.800761Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kaggle_secrets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkaggle_secrets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UserSecretsClient\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent, LlmAgent, SequentialAgent\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kaggle_secrets'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CORE IMPORTS\n",
    "# =============================================================================\n",
    "# Standard library imports for type hints, OS operations, and utilities\n",
    "from typing import Any, Dict, List, Optional\n",
    "import os\n",
    "import uuid\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# =============================================================================\n",
    "# KAGGLE SECRETS - For secure API key management\n",
    "# =============================================================================\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# =============================================================================\n",
    "# DATA MANIPULATION\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "\n",
    "# =============================================================================\n",
    "# GOOGLE ADK (Agent Development Kit) - Core agent framework\n",
    "# =============================================================================\n",
    "from google.adk.agents import Agent, LlmAgent, SequentialAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "from google.genai import types\n",
    "from google.adk.tools import AgentTool, FunctionTool, google_search\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google import generativeai as genai\n",
    "\n",
    "print(\"‚úÖ ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è API Configuration\n",
    "\n",
    "Configure the Google Gemini API for LLM-powered agent capabilities:\n",
    "- **API Key**: Loaded securely from Kaggle Secrets\n",
    "- **Model**: Gemini 2.5 Flash for fast, intelligent responses\n",
    "- **Temperature**: 0.3 for more focused, consistent outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T19:13:26.612663Z",
     "iopub.status.busy": "2025-11-30T19:13:26.612337Z",
     "iopub.status.idle": "2025-11-30T19:13:26.758227Z",
     "shell.execute_reply": "2025-11-30T19:13:26.757237Z",
     "shell.execute_reply.started": "2025-11-30T19:13:26.612640Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini API key setup complete.\n",
      "\n",
      "============================================================\n",
      "                    AGENT CONFIGURATION                     \n",
      "============================================================\n",
      "project.................. \n",
      "model.................... models/gemini-2.5-flash\n",
      "max_tokens............... 2000\n",
      "temperature.............. 0.3\n",
      "version.................. 1.0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GOOGLE GEMINI API CONFIGURATION\n",
    "# =============================================================================\n",
    "# Load API Key securely from Kaggle Secrets vault\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "    \n",
    "    # Configure genai with the API key for all subsequent calls\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    \n",
    "    print(\"‚úÖ Gemini API key setup complete.\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Kaggle Secrets not available. Ensure you're in a Kaggle Notebook.\")\n",
    "except KeyError:\n",
    "    print(\"üîë Authentication Error: Add 'GOOGLE_API_KEY' to Kaggle secrets.\")\n",
    "\n",
    "# =============================================================================\n",
    "# AGENT CONFIGURATION PARAMETERS\n",
    "# =============================================================================\n",
    "# These settings control the behavior of our Analytics Agent\n",
    "CONFIG = {\n",
    "    \"project\": \"\",                      # Project identifier (optional)\n",
    "    \"model\": \"models/gemini-2.5-flash\", # LLM model to use\n",
    "    \"max_tokens\": 2000,                 # Maximum response length\n",
    "    \"temperature\": 0.3,                 # Lower = more focused responses\n",
    "    \"version\": \"1.0\"                    # Agent version for tracking\n",
    "}\n",
    "\n",
    "# Display configuration summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"{'AGENT CONFIGURATION':^60}\")\n",
    "print(f\"{'='*60}\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"{k:.<25} {v}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T19:13:29.079100Z",
     "iopub.status.busy": "2025-11-30T19:13:29.078791Z",
     "iopub.status.idle": "2025-11-30T19:13:29.084814Z",
     "shell.execute_reply": "2025-11-30T19:13:29.083687Z",
     "shell.execute_reply.started": "2025-11-30T19:13:29.079076Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retry configuration defined.\n"
     ]
    }
   ],
   "source": [
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5, # Maximum retry attempts\n",
    "    exp_base=2, # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504] # HTTP errors retry\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Retry configuration defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T19:13:31.397034Z",
     "iopub.status.busy": "2025-11-30T19:13:31.395980Z",
     "iopub.status.idle": "2025-11-30T19:13:31.445328Z",
     "shell.execute_reply": "2025-11-30T19:13:31.444222Z",
     "shell.execute_reply.started": "2025-11-30T19:13:31.396997Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-flash-latest\n",
      "models/gemini-flash-lite-latest\n",
      "models/gemini-pro-latest\n",
      "models/gemini-2.5-flash-lite\n",
      "models/gemini-2.5-flash-image-preview\n",
      "models/gemini-2.5-flash-image\n",
      "models/gemini-2.5-flash-preview-09-2025\n",
      "models/gemini-2.5-flash-lite-preview-09-2025\n",
      "models/gemini-3-pro-preview\n",
      "models/gemini-3-pro-image-preview\n",
      "models/nano-banana-pro-preview\n",
      "models/gemini-robotics-er-1.5-preview\n",
      "models/gemini-2.5-computer-use-preview-10-2025\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "models/aqa\n",
      "models/imagen-4.0-generate-preview-06-06\n",
      "models/imagen-4.0-ultra-generate-preview-06-06\n",
      "models/imagen-4.0-generate-001\n",
      "models/imagen-4.0-ultra-generate-001\n",
      "models/imagen-4.0-fast-generate-001\n",
      "models/veo-2.0-generate-001\n",
      "models/veo-3.0-generate-001\n",
      "models/veo-3.0-fast-generate-001\n",
      "models/veo-3.1-generate-preview\n",
      "models/veo-3.1-fast-generate-preview\n",
      "models/gemini-2.0-flash-live-001\n",
      "models/gemini-live-2.5-flash-preview\n",
      "models/gemini-2.5-flash-live-preview\n",
      "models/gemini-2.5-flash-native-audio-latest\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025\n"
     ]
    }
   ],
   "source": [
    "# Lists all LLM models available in your Google Generative AI account\n",
    "models = genai.list_models()\n",
    "\n",
    "# Prints each model name\n",
    "for model in models:\n",
    "    print(model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Feature 4: Observability - Logging, Tracing, and Metrics\n",
    "\n",
    "This section implements comprehensive **observability** for the AI agent:\n",
    "\n",
    "| Component | Purpose |\n",
    "|-----------|---------|\n",
    "| **Logging** | Records all agent actions, errors, and decisions |\n",
    "| **Tracing** | Tracks request flow through agent operations with unique trace IDs |\n",
    "| **Metrics** | Collects quantifiable measurements (response times, call counts, errors) |\n",
    "\n",
    "This is essential for debugging, monitoring performance, and understanding agent behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE 4: OBSERVABILITY - LOGGING, TRACING, AND METRICS\n",
    "# =============================================================================\n",
    "# This class provides comprehensive monitoring capabilities for the AI agent\n",
    "\n",
    "class AgentObservability:\n",
    "    \"\"\"\n",
    "    Observability system for AI Agents providing:\n",
    "    - Logging: Record events, errors, and decisions\n",
    "    - Tracing: Track request flow with unique trace IDs\n",
    "    - Metrics: Collect performance measurements\n",
    "    \n",
    "    This is a key feature demonstrating observability concepts from the course.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, agent_name: str = \"AnalyticsAgent\"):\n",
    "        \"\"\"\n",
    "        Initialize the observability system.\n",
    "        \n",
    "        Args:\n",
    "            agent_name: Name of the agent for logging identification\n",
    "        \"\"\"\n",
    "        self.agent_name = agent_name\n",
    "        \n",
    "        # ---------------------------------------------------------------------\n",
    "        # LOGGING SETUP\n",
    "        # ---------------------------------------------------------------------\n",
    "        # Configure logging to capture all agent activities\n",
    "        self.logger = logging.getLogger(agent_name)\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "        \n",
    "        # Create console handler with formatting\n",
    "        if not self.logger.handlers:\n",
    "            handler = logging.StreamHandler()\n",
    "            handler.setLevel(logging.DEBUG)\n",
    "            formatter = logging.Formatter(\n",
    "                '%(asctime)s | %(name)s | %(levelname)s | %(message)s',\n",
    "                datefmt='%Y-%m-%d %H:%M:%S'\n",
    "            )\n",
    "            handler.setFormatter(formatter)\n",
    "            self.logger.addHandler(handler)\n",
    "        \n",
    "        # ---------------------------------------------------------------------\n",
    "        # METRICS STORAGE\n",
    "        # ---------------------------------------------------------------------\n",
    "        # Store quantifiable measurements for analysis\n",
    "        self.metrics = {\n",
    "            'total_requests': 0,           # Total number of questions asked\n",
    "            'successful_requests': 0,      # Requests that completed successfully\n",
    "            'failed_requests': 0,          # Requests that encountered errors\n",
    "            'total_tokens_used': 0,        # Estimated token usage\n",
    "            'total_response_time': 0.0,    # Cumulative response time\n",
    "            'avg_response_time': 0.0,      # Average response time\n",
    "            'requests_per_tool': defaultdict(int),  # Calls per analysis tool\n",
    "            'errors_by_type': defaultdict(int),     # Error counts by type\n",
    "        }\n",
    "        \n",
    "        # ---------------------------------------------------------------------\n",
    "        # TRACING STORAGE\n",
    "        # ---------------------------------------------------------------------\n",
    "        # Store trace records for debugging and analysis\n",
    "        self.traces: List[Dict[str, Any]] = []\n",
    "        self.current_trace_id: Optional[str] = None\n",
    "        \n",
    "        self.logger.info(f\"üîç Observability initialized for {agent_name}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # LOGGING METHODS\n",
    "    # =========================================================================\n",
    "    \n",
    "    def log_info(self, message: str, trace_id: Optional[str] = None):\n",
    "        \"\"\"Log informational message.\"\"\"\n",
    "        trace_str = f\"[Trace: {trace_id}] \" if trace_id else \"\"\n",
    "        self.logger.info(f\"{trace_str}{message}\")\n",
    "    \n",
    "    def log_warning(self, message: str, trace_id: Optional[str] = None):\n",
    "        \"\"\"Log warning message.\"\"\"\n",
    "        trace_str = f\"[Trace: {trace_id}] \" if trace_id else \"\"\n",
    "        self.logger.warning(f\"{trace_str}{message}\")\n",
    "    \n",
    "    def log_error(self, message: str, error_type: str = \"general\", trace_id: Optional[str] = None):\n",
    "        \"\"\"Log error message and track in metrics.\"\"\"\n",
    "        trace_str = f\"[Trace: {trace_id}] \" if trace_id else \"\"\n",
    "        self.logger.error(f\"{trace_str}{message}\")\n",
    "        self.metrics['errors_by_type'][error_type] += 1\n",
    "        self.metrics['failed_requests'] += 1\n",
    "    \n",
    "    def log_debug(self, message: str, trace_id: Optional[str] = None):\n",
    "        \"\"\"Log debug message.\"\"\"\n",
    "        trace_str = f\"[Trace: {trace_id}] \" if trace_id else \"\"\n",
    "        self.logger.debug(f\"{trace_str}{message}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # TRACING METHODS\n",
    "    # =========================================================================\n",
    "    \n",
    "    def start_trace(self, operation: str, metadata: Optional[Dict] = None) -> str:\n",
    "        \"\"\"\n",
    "        Start a new trace for tracking an operation.\n",
    "        \n",
    "        Args:\n",
    "            operation: Name of the operation being traced\n",
    "            metadata: Optional additional context\n",
    "            \n",
    "        Returns:\n",
    "            Unique trace ID for this operation\n",
    "        \"\"\"\n",
    "        trace_id = str(uuid.uuid4())[:8]  # Short UUID for readability\n",
    "        self.current_trace_id = trace_id\n",
    "        \n",
    "        trace_record = {\n",
    "            'trace_id': trace_id,\n",
    "            'operation': operation,\n",
    "            'start_time': datetime.now(),\n",
    "            'end_time': None,\n",
    "            'duration_ms': None,\n",
    "            'status': 'in_progress',\n",
    "            'metadata': metadata or {},\n",
    "            'spans': []  # Child operations\n",
    "        }\n",
    "        self.traces.append(trace_record)\n",
    "        \n",
    "        self.log_info(f\"‚ñ∂Ô∏è Started: {operation}\", trace_id)\n",
    "        return trace_id\n",
    "    \n",
    "    def add_span(self, trace_id: str, span_name: str, duration_ms: float, status: str = \"success\"):\n",
    "        \"\"\"Add a child span to an existing trace.\"\"\"\n",
    "        for trace in self.traces:\n",
    "            if trace['trace_id'] == trace_id:\n",
    "                trace['spans'].append({\n",
    "                    'name': span_name,\n",
    "                    'duration_ms': duration_ms,\n",
    "                    'status': status,\n",
    "                    'timestamp': datetime.now()\n",
    "                })\n",
    "                break\n",
    "    \n",
    "    def end_trace(self, trace_id: str, status: str = \"success\"):\n",
    "        \"\"\"\n",
    "        End a trace and calculate duration.\n",
    "        \n",
    "        Args:\n",
    "            trace_id: The trace ID to end\n",
    "            status: Final status ('success' or 'error')\n",
    "        \"\"\"\n",
    "        for trace in self.traces:\n",
    "            if trace['trace_id'] == trace_id:\n",
    "                trace['end_time'] = datetime.now()\n",
    "                trace['duration_ms'] = (trace['end_time'] - trace['start_time']).total_seconds() * 1000\n",
    "                trace['status'] = status\n",
    "                \n",
    "                self.log_info(f\"‚èπÔ∏è Completed: {trace['operation']} ({trace['duration_ms']:.2f}ms)\", trace_id)\n",
    "                break\n",
    "        \n",
    "        self.current_trace_id = None\n",
    "    \n",
    "    # =========================================================================\n",
    "    # METRICS METHODS\n",
    "    # =========================================================================\n",
    "    \n",
    "    def record_request(self, response_time: float, tool_used: str = \"ask\", success: bool = True):\n",
    "        \"\"\"\n",
    "        Record metrics for a completed request.\n",
    "        \n",
    "        Args:\n",
    "            response_time: Time taken for the request in seconds\n",
    "            tool_used: Which analysis tool was used\n",
    "            success: Whether the request succeeded\n",
    "        \"\"\"\n",
    "        self.metrics['total_requests'] += 1\n",
    "        self.metrics['total_response_time'] += response_time\n",
    "        self.metrics['requests_per_tool'][tool_used] += 1\n",
    "        \n",
    "        if success:\n",
    "            self.metrics['successful_requests'] += 1\n",
    "        else:\n",
    "            self.metrics['failed_requests'] += 1\n",
    "        \n",
    "        # Update average response time\n",
    "        self.metrics['avg_response_time'] = (\n",
    "            self.metrics['total_response_time'] / self.metrics['total_requests']\n",
    "        )\n",
    "    \n",
    "    def get_metrics_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get a summary of all collected metrics.\"\"\"\n",
    "        return {\n",
    "            'total_requests': self.metrics['total_requests'],\n",
    "            'success_rate': (\n",
    "                self.metrics['successful_requests'] / max(self.metrics['total_requests'], 1) * 100\n",
    "            ),\n",
    "            'avg_response_time_sec': round(self.metrics['avg_response_time'], 3),\n",
    "            'total_errors': self.metrics['failed_requests'],\n",
    "            'requests_per_tool': dict(self.metrics['requests_per_tool']),\n",
    "            'errors_by_type': dict(self.metrics['errors_by_type']),\n",
    "        }\n",
    "    \n",
    "    def print_metrics_report(self):\n",
    "        \"\"\"Print a formatted metrics report.\"\"\"\n",
    "        metrics = self.get_metrics_summary()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"üìä AGENT OBSERVABILITY METRICS REPORT\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Total Requests:       {metrics['total_requests']}\")\n",
    "        print(f\"Success Rate:         {metrics['success_rate']:.1f}%\")\n",
    "        print(f\"Avg Response Time:    {metrics['avg_response_time_sec']:.3f}s\")\n",
    "        print(f\"Total Errors:         {metrics['total_errors']}\")\n",
    "        print(\"-\" * 60)\n",
    "        print(\"Requests by Tool:\")\n",
    "        for tool, count in metrics['requests_per_tool'].items():\n",
    "            print(f\"  - {tool}: {count}\")\n",
    "        if metrics['errors_by_type']:\n",
    "            print(\"-\" * 60)\n",
    "            print(\"Errors by Type:\")\n",
    "            for error_type, count in metrics['errors_by_type'].items():\n",
    "                print(f\"  - {error_type}: {count}\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    def get_recent_traces(self, n: int = 5) -> List[Dict]:\n",
    "        \"\"\"Get the n most recent traces.\"\"\"\n",
    "        return self.traces[-n:]\n",
    "\n",
    "print(\"‚úÖ AgentObservability class loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Feature 3: Sessions & Memory\n",
    "\n",
    "This section implements **session management and memory** for the AI agent:\n",
    "\n",
    "| Component | Purpose |\n",
    "|-----------|---------|\n",
    "| **SessionManager** | Manages user sessions with unique IDs and state persistence |\n",
    "| **InMemorySessionService** | Stores session data during runtime (ADK component) |\n",
    "| **MemoryBank** | Long-term memory for storing and recalling insights |\n",
    "| **Context Engineering** | Compacts context to manage token limits |\n",
    "\n",
    "This enables the agent to maintain conversation state and learn from interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE 3: SESSIONS & MEMORY\n",
    "# =============================================================================\n",
    "# This module provides session management and memory capabilities for the agent\n",
    "\n",
    "class MemoryBank:\n",
    "    \"\"\"\n",
    "    Long-term memory storage for the AI Agent.\n",
    "    \n",
    "    Stores insights, user preferences, and learned patterns that persist\n",
    "    across conversations within a session. Implements the Memory Bank\n",
    "    pattern from the AI Agents course.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the memory bank with categorized storage.\"\"\"\n",
    "        # Different memory categories for organized storage\n",
    "        self.insights_memory: Dict[str, Any] = {}      # Stored analysis insights\n",
    "        self.user_preferences: Dict[str, Any] = {}     # User-specific preferences\n",
    "        self.conversation_summaries: List[str] = []    # Summarized past conversations\n",
    "        self.learned_patterns: Dict[str, Any] = {}     # Patterns learned from data\n",
    "        self.frequently_asked: Dict[str, int] = {}     # Track common questions\n",
    "        \n",
    "    def store(self, category: str, key: str, value: Any):\n",
    "        \"\"\"\n",
    "        Store information in the appropriate memory category.\n",
    "        \n",
    "        Args:\n",
    "            category: 'insights', 'preferences', 'patterns', or 'summaries'\n",
    "            key: Identifier for the stored value\n",
    "            value: Data to store\n",
    "        \"\"\"\n",
    "        if category == 'insights':\n",
    "            self.insights_memory[key] = {\n",
    "                'value': value,\n",
    "                'timestamp': datetime.now(),\n",
    "                'access_count': 0\n",
    "            }\n",
    "        elif category == 'preferences':\n",
    "            self.user_preferences[key] = value\n",
    "        elif category == 'patterns':\n",
    "            self.learned_patterns[key] = value\n",
    "        elif category == 'summaries':\n",
    "            self.conversation_summaries.append(value)\n",
    "    \n",
    "    def recall(self, category: str, key: str) -> Optional[Any]:\n",
    "        \"\"\"\n",
    "        Recall information from memory.\n",
    "        \n",
    "        Args:\n",
    "            category: Memory category to search\n",
    "            key: Identifier to look up\n",
    "            \n",
    "        Returns:\n",
    "            Stored value or None if not found\n",
    "        \"\"\"\n",
    "        if category == 'insights' and key in self.insights_memory:\n",
    "            self.insights_memory[key]['access_count'] += 1\n",
    "            return self.insights_memory[key]['value']\n",
    "        elif category == 'preferences':\n",
    "            return self.user_preferences.get(key)\n",
    "        elif category == 'patterns':\n",
    "            return self.learned_patterns.get(key)\n",
    "        return None\n",
    "    \n",
    "    def track_question(self, question: str):\n",
    "        \"\"\"Track frequently asked questions for pattern learning.\"\"\"\n",
    "        # Normalize question for comparison\n",
    "        normalized = question.lower().strip()\n",
    "        self.frequently_asked[normalized] = self.frequently_asked.get(normalized, 0) + 1\n",
    "    \n",
    "    def get_top_questions(self, n: int = 5) -> List[tuple]:\n",
    "        \"\"\"Get the most frequently asked questions.\"\"\"\n",
    "        sorted_questions = sorted(\n",
    "            self.frequently_asked.items(), \n",
    "            key=lambda x: x[1], \n",
    "            reverse=True\n",
    "        )\n",
    "        return sorted_questions[:n]\n",
    "    \n",
    "    def get_memory_stats(self) -> Dict[str, int]:\n",
    "        \"\"\"Get statistics about memory usage.\"\"\"\n",
    "        return {\n",
    "            'stored_insights': len(self.insights_memory),\n",
    "            'user_preferences': len(self.user_preferences),\n",
    "            'conversation_summaries': len(self.conversation_summaries),\n",
    "            'learned_patterns': len(self.learned_patterns),\n",
    "            'tracked_questions': len(self.frequently_asked)\n",
    "        }\n",
    "\n",
    "\n",
    "class SessionManager:\n",
    "    \"\"\"\n",
    "    Session management for the AI Agent using InMemorySessionService pattern.\n",
    "    \n",
    "    Manages:\n",
    "    - Session creation and lifecycle\n",
    "    - State persistence within sessions\n",
    "    - Context engineering (compaction for token limits)\n",
    "    - Integration with MemoryBank for long-term storage\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize session manager with in-memory storage.\"\"\"\n",
    "        # ---------------------------------------------------------------------\n",
    "        # SESSION SERVICE (similar to ADK InMemorySessionService)\n",
    "        # ---------------------------------------------------------------------\n",
    "        self.sessions: Dict[str, Dict[str, Any]] = {}\n",
    "        self.active_session_id: Optional[str] = None\n",
    "        \n",
    "        # ---------------------------------------------------------------------\n",
    "        # MEMORY BANK for long-term storage\n",
    "        # ---------------------------------------------------------------------\n",
    "        self.memory_bank = MemoryBank()\n",
    "        \n",
    "        # Session configuration\n",
    "        self.max_context_length = 4000  # Characters for context compaction\n",
    "        self.session_timeout_minutes = 60\n",
    "        \n",
    "    def create_session(self, user_id: Optional[str] = None) -> str:\n",
    "        \"\"\"\n",
    "        Create a new session for a user.\n",
    "        \n",
    "        Args:\n",
    "            user_id: Optional user identifier\n",
    "            \n",
    "        Returns:\n",
    "            Unique session ID\n",
    "        \"\"\"\n",
    "        session_id = str(uuid.uuid4())[:12]\n",
    "        \n",
    "        self.sessions[session_id] = {\n",
    "            'session_id': session_id,\n",
    "            'user_id': user_id or 'anonymous',\n",
    "            'created_at': datetime.now(),\n",
    "            'last_activity': datetime.now(),\n",
    "            'state': {\n",
    "                'conversation_history': [],\n",
    "                'context_window': [],\n",
    "                'insights_generated': [],\n",
    "                'questions_asked': 0,\n",
    "            },\n",
    "            'metadata': {\n",
    "                'total_interactions': 0,\n",
    "                'session_duration_minutes': 0,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.active_session_id = session_id\n",
    "        return session_id\n",
    "    \n",
    "    def get_session(self, session_id: str) -> Optional[Dict]:\n",
    "        \"\"\"Get session data by ID.\"\"\"\n",
    "        session = self.sessions.get(session_id)\n",
    "        if session:\n",
    "            session['last_activity'] = datetime.now()\n",
    "            # Update session duration\n",
    "            duration = (datetime.now() - session['created_at']).total_seconds() / 60\n",
    "            session['metadata']['session_duration_minutes'] = round(duration, 2)\n",
    "        return session\n",
    "    \n",
    "    def update_state(self, session_id: str, key: str, value: Any):\n",
    "        \"\"\"Update session state.\"\"\"\n",
    "        if session_id in self.sessions:\n",
    "            self.sessions[session_id]['state'][key] = value\n",
    "            self.sessions[session_id]['last_activity'] = datetime.now()\n",
    "    \n",
    "    def add_to_history(self, session_id: str, role: str, content: str):\n",
    "        \"\"\"Add a message to conversation history.\"\"\"\n",
    "        if session_id in self.sessions:\n",
    "            self.sessions[session_id]['state']['conversation_history'].append({\n",
    "                'role': role,\n",
    "                'content': content,\n",
    "                'timestamp': datetime.now()\n",
    "            })\n",
    "            self.sessions[session_id]['metadata']['total_interactions'] += 1\n",
    "            \n",
    "            if role == 'user':\n",
    "                self.sessions[session_id]['state']['questions_asked'] += 1\n",
    "                self.memory_bank.track_question(content)\n",
    "    \n",
    "    def get_conversation_history(self, session_id: str) -> List[Dict]:\n",
    "        \"\"\"Get conversation history for a session.\"\"\"\n",
    "        session = self.get_session(session_id)\n",
    "        return session['state']['conversation_history'] if session else []\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CONTEXT ENGINEERING - Context Compaction\n",
    "    # =========================================================================\n",
    "    \n",
    "    def compact_context(self, session_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Compact conversation context to manage token limits.\n",
    "        \n",
    "        This implements context engineering by summarizing older messages\n",
    "        while keeping recent context intact.\n",
    "        \n",
    "        Args:\n",
    "            session_id: Session to compact context for\n",
    "            \n",
    "        Returns:\n",
    "            Compacted context string\n",
    "        \"\"\"\n",
    "        session = self.get_session(session_id)\n",
    "        if not session:\n",
    "            return \"\"\n",
    "        \n",
    "        history = session['state']['conversation_history']\n",
    "        \n",
    "        if len(history) <= 3:\n",
    "            # Keep all if history is short\n",
    "            return self._format_history(history)\n",
    "        \n",
    "        # Keep last 3 exchanges, summarize the rest\n",
    "        recent = history[-3:]\n",
    "        older = history[:-3]\n",
    "        \n",
    "        # Create summary of older context\n",
    "        summary_points = []\n",
    "        for msg in older:\n",
    "            if msg['role'] == 'user':\n",
    "                summary_points.append(f\"Asked about: {msg['content'][:50]}...\")\n",
    "        \n",
    "        compacted = \"üìù Earlier in conversation:\\n\"\n",
    "        compacted += \"\\n\".join(f\"  - {point}\" for point in summary_points[-5:])\n",
    "        compacted += \"\\n\\nüìç Recent context:\\n\"\n",
    "        compacted += self._format_history(recent)\n",
    "        \n",
    "        return compacted[:self.max_context_length]\n",
    "    \n",
    "    def _format_history(self, history: List[Dict]) -> str:\n",
    "        \"\"\"Format conversation history as string.\"\"\"\n",
    "        formatted = []\n",
    "        for msg in history:\n",
    "            role = \"User\" if msg['role'] == 'user' else \"Agent\"\n",
    "            formatted.append(f\"{role}: {msg['content']}\")\n",
    "        return \"\\n\".join(formatted)\n",
    "    \n",
    "    def end_session(self, session_id: str):\n",
    "        \"\"\"\n",
    "        End a session and store summary in long-term memory.\n",
    "        \n",
    "        Args:\n",
    "            session_id: Session to end\n",
    "        \"\"\"\n",
    "        session = self.get_session(session_id)\n",
    "        if session:\n",
    "            # Create session summary for memory bank\n",
    "            summary = {\n",
    "                'session_id': session_id,\n",
    "                'duration_minutes': session['metadata']['session_duration_minutes'],\n",
    "                'total_questions': session['state']['questions_asked'],\n",
    "                'ended_at': datetime.now()\n",
    "            }\n",
    "            \n",
    "            # Store in long-term memory\n",
    "            self.memory_bank.store('summaries', session_id, str(summary))\n",
    "            \n",
    "            # Mark session as ended\n",
    "            session['state']['ended'] = True\n",
    "    \n",
    "    def get_session_stats(self, session_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get statistics for a session.\"\"\"\n",
    "        session = self.get_session(session_id)\n",
    "        if not session:\n",
    "            return {}\n",
    "        \n",
    "        return {\n",
    "            'session_id': session_id,\n",
    "            'user_id': session['user_id'],\n",
    "            'created_at': session['created_at'].strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'duration_minutes': session['metadata']['session_duration_minutes'],\n",
    "            'total_interactions': session['metadata']['total_interactions'],\n",
    "            'questions_asked': session['state']['questions_asked'],\n",
    "            'memory_stats': self.memory_bank.get_memory_stats()\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Sessions & Memory classes loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Loading Dataset - Bank Customer Churn\n",
    "\n",
    "Load the Bank Customer Churn Prediction dataset from Kaggle:\n",
    "- **Source**: [Kaggle Dataset](https://www.kaggle.com/datasets/saurabhbadole/bank-customer-churn-prediction-dataset)\n",
    "- **Size**: 10,000 customer records\n",
    "- **Target**: `Exited` column (1 = churned, 0 = retained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T19:13:33.774832Z",
     "iopub.status.busy": "2025-11-30T19:13:33.774517Z",
     "iopub.status.idle": "2025-11-30T19:13:33.812695Z",
     "shell.execute_reply": "2025-11-30T19:13:33.811567Z",
     "shell.execute_reply.started": "2025-11-30T19:13:33.774809Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded: 10000 rows\n",
      "üìä Columns: ['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited']\n"
     ]
    }
   ],
   "source": [
    "# Loading DataFrame\n",
    "# Dataset URL - https://www.kaggle.com/datasets/saurabhbadole/bank-customer-churn-prediction-dataset\n",
    "df = pd.read_csv(\"/kaggle/input/bank-customer-churn-prediction-dataset/Churn_Modelling.csv\")\n",
    "\n",
    "# Quick check\n",
    "print(f\"‚úÖ Data loaded: {len(df)} rows\")\n",
    "print(f\"üìä Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T19:13:35.882267Z",
     "iopub.status.busy": "2025-11-30T19:13:35.881875Z",
     "iopub.status.idle": "2025-11-30T19:13:35.897271Z",
     "shell.execute_reply": "2025-11-30T19:13:35.896424Z",
     "shell.execute_reply.started": "2025-11-30T19:13:35.882237Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking sample output\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Analytics AI Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T19:32:24.716816Z",
     "iopub.status.busy": "2025-11-30T19:32:24.715747Z",
     "iopub.status.idle": "2025-11-30T19:32:24.760424Z",
     "shell.execute_reply": "2025-11-30T19:32:24.759280Z",
     "shell.execute_reply.started": "2025-11-30T19:32:24.716778Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AnalyticsAgent class loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import google.generativeai as gen\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "class AnalyticsAgent:\n",
    "    \"\"\"\n",
    "    Analytics Agent for generating executive insights on Bank Customer Churn data.\n",
    "    Powered by Google Gemini for intelligent Q&A.\n",
    "    \n",
    "    Now includes full observability integration with:\n",
    "    - Logging: All operations are logged with timestamps\n",
    "    - Tracing: Each request gets a unique trace ID for debugging\n",
    "    - Metrics: Performance and usage metrics are collected\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe: pd.DataFrame, enable_observability: bool = True):\n",
    "        \"\"\"\n",
    "        Initialize the Analytics Agent with the dataset.\n",
    "        \n",
    "        Args:\n",
    "            dataframe: pandas DataFrame containing bank customer churn data\n",
    "            enable_observability: Whether to enable logging, tracing, and metrics\n",
    "        \"\"\"\n",
    "        self.df = dataframe.copy()\n",
    "        self.insights = {}\n",
    "        self.chat_history = []\n",
    "        \n",
    "        # Initialize observability system\n",
    "        self.observability_enabled = enable_observability\n",
    "        if enable_observability:\n",
    "            self.observability = AgentObservability(agent_name=\"AnalyticsAgent\")\n",
    "            self.observability.log_info(\"üöÄ AnalyticsAgent initialized with observability enabled\")\n",
    "        else:\n",
    "            self.observability = None\n",
    "            \n",
    "    def _trace_operation(self, operation_name: str, metadata: dict = None):\n",
    "        \"\"\"Helper to start a trace if observability is enabled.\"\"\"\n",
    "        if self.observability:\n",
    "            return self.observability.start_trace(operation_name, metadata)\n",
    "        return None\n",
    "    \n",
    "    def _end_trace(self, trace_id: str, status: str = \"success\"):\n",
    "        \"\"\"Helper to end a trace if observability is enabled.\"\"\"\n",
    "        if self.observability and trace_id:\n",
    "            self.observability.end_trace(trace_id, status)\n",
    "            \n",
    "    def _log(self, level: str, message: str, trace_id: str = None):\n",
    "        \"\"\"Helper to log messages if observability is enabled.\"\"\"\n",
    "        if self.observability:\n",
    "            if level == \"info\":\n",
    "                self.observability.log_info(message, trace_id)\n",
    "            elif level == \"warning\":\n",
    "                self.observability.log_warning(message, trace_id)\n",
    "            elif level == \"error\":\n",
    "                self.observability.log_error(message, trace_id=trace_id)\n",
    "            elif level == \"debug\":\n",
    "                self.observability.log_debug(message, trace_id)\n",
    "        \n",
    "    def generate_executive_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Generate a comprehensive executive summary with key metrics.\"\"\"\n",
    "        trace_id = self._trace_operation(\"generate_executive_summary\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            summary = {\n",
    "                'total_customers': int(len(self.df)),\n",
    "                'churn_rate': float(self._calculate_churn_rate()),\n",
    "                'avg_customer_age': float(self.df['Age'].mean()),\n",
    "                'avg_account_balance': float(self.df['Balance'].mean()),\n",
    "                'avg_estimated_salary': float(self.df['EstimatedSalary'].mean()),\n",
    "                'active_member_rate': float((self.df['IsActiveMember'].sum() / len(self.df)) * 100),\n",
    "                'credit_card_holder_rate': float((self.df['HasCrCard'].sum() / len(self.df)) * 100),\n",
    "            }\n",
    "            self.insights['executive_summary'] = summary\n",
    "            \n",
    "            self._log(\"info\", f\"Executive summary generated: {summary['total_customers']} customers, {summary['churn_rate']:.2f}% churn\", trace_id)\n",
    "            self._end_trace(trace_id, \"success\")\n",
    "            \n",
    "            if self.observability:\n",
    "                self.observability.add_span(trace_id, \"calculate_metrics\", (time.time() - start_time) * 1000)\n",
    "            \n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            self._log(\"error\", f\"Failed to generate executive summary: {str(e)}\", trace_id)\n",
    "            self._end_trace(trace_id, \"error\")\n",
    "            raise\n",
    "    \n",
    "    def _calculate_churn_rate(self) -> float:\n",
    "        \"\"\"Calculate overall churn rate as percentage.\"\"\"\n",
    "        return (self.df['Exited'].sum() / len(self.df)) * 100\n",
    "    \n",
    "    def analyze_churn_by_geography(self) -> pd.DataFrame:\n",
    "        \"\"\"Analyze churn rates across different geographies.\"\"\"\n",
    "        trace_id = self._trace_operation(\"analyze_churn_by_geography\")\n",
    "        \n",
    "        try:\n",
    "            geo_analysis = self.df.groupby('Geography', observed=True).agg({\n",
    "                'Exited': ['sum', 'count', 'mean'],\n",
    "                'Balance': 'mean',\n",
    "                'EstimatedSalary': 'mean'\n",
    "            }).round(2)\n",
    "            geo_analysis.columns = ['Churned_Customers', 'Total_Customers', 'Churn_Rate', \n",
    "                                    'Avg_Balance', 'Avg_Salary']\n",
    "            geo_analysis['Churn_Rate'] = geo_analysis['Churn_Rate'] * 100\n",
    "            self.insights['geography_analysis'] = geo_analysis\n",
    "            \n",
    "            self._log(\"info\", f\"Geography analysis complete: {len(geo_analysis)} regions analyzed\", trace_id)\n",
    "            self._end_trace(trace_id, \"success\")\n",
    "            return geo_analysis\n",
    "        except Exception as e:\n",
    "            self._log(\"error\", f\"Geography analysis failed: {str(e)}\", trace_id)\n",
    "            self._end_trace(trace_id, \"error\")\n",
    "            raise\n",
    "    \n",
    "    def analyze_churn_by_demographics(self) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Analyze churn patterns by demographic factors (age, gender).\"\"\"\n",
    "        trace_id = self._trace_operation(\"analyze_churn_by_demographics\")\n",
    "        \n",
    "        try:\n",
    "            self.df['AgeGroup'] = pd.cut(self.df['Age'], \n",
    "                                          bins=[0, 30, 40, 50, 60, 100],\n",
    "                                          labels=['<30', '30-40', '40-50', '50-60', '60+'])\n",
    "            \n",
    "            age_analysis = self.df.groupby('AgeGroup', observed=True).agg({\n",
    "                'Exited': ['sum', 'count', 'mean'],\n",
    "                'Balance': 'mean'\n",
    "            }).round(2)\n",
    "            age_analysis.columns = ['Churned', 'Total', 'Churn_Rate', 'Avg_Balance']\n",
    "            age_analysis['Churn_Rate'] = age_analysis['Churn_Rate'] * 100\n",
    "            \n",
    "            gender_analysis = self.df.groupby('Gender', observed=True).agg({\n",
    "                'Exited': ['sum', 'count', 'mean'],\n",
    "                'Balance': 'mean',\n",
    "                'CreditScore': 'mean'\n",
    "            }).round(2)\n",
    "            gender_analysis.columns = ['Churned', 'Total', 'Churn_Rate', 'Avg_Balance', 'Avg_CreditScore']\n",
    "            gender_analysis['Churn_Rate'] = gender_analysis['Churn_Rate'] * 100\n",
    "            \n",
    "            demographics = {\n",
    "                'age_analysis': age_analysis,\n",
    "                'gender_analysis': gender_analysis\n",
    "            }\n",
    "            self.insights['demographics'] = demographics\n",
    "            \n",
    "            self._log(\"info\", \"Demographics analysis complete: age groups and gender analyzed\", trace_id)\n",
    "            self._end_trace(trace_id, \"success\")\n",
    "            return demographics\n",
    "        except Exception as e:\n",
    "            self._log(\"error\", f\"Demographics analysis failed: {str(e)}\", trace_id)\n",
    "            self._end_trace(trace_id, \"error\")\n",
    "            raise\n",
    "    \n",
    "    def analyze_product_engagement(self) -> pd.DataFrame:\n",
    "        \"\"\"Analyze churn based on number of products and engagement metrics.\"\"\"\n",
    "        trace_id = self._trace_operation(\"analyze_product_engagement\")\n",
    "        \n",
    "        try:\n",
    "            product_analysis = self.df.groupby('NumOfProducts', observed=True).agg({\n",
    "                'Exited': ['sum', 'count', 'mean'],\n",
    "                'Balance': 'mean',\n",
    "                'Tenure': 'mean',\n",
    "                'IsActiveMember': 'mean'\n",
    "            }).round(2)\n",
    "            product_analysis.columns = ['Churned', 'Total', 'Churn_Rate', \n",
    "                                        'Avg_Balance', 'Avg_Tenure', 'Active_Rate']\n",
    "            product_analysis['Churn_Rate'] = product_analysis['Churn_Rate'] * 100\n",
    "            product_analysis['Active_Rate'] = product_analysis['Active_Rate'] * 100\n",
    "            self.insights['product_engagement'] = product_analysis\n",
    "            \n",
    "            self._log(\"info\", \"Product engagement analysis complete\", trace_id)\n",
    "            self._end_trace(trace_id, \"success\")\n",
    "            return product_analysis\n",
    "        except Exception as e:\n",
    "            self._log(\"error\", f\"Product engagement analysis failed: {str(e)}\", trace_id)\n",
    "            self._end_trace(trace_id, \"error\")\n",
    "            raise\n",
    "    \n",
    "    def identify_high_risk_segments(self) -> pd.DataFrame:\n",
    "        \"\"\"Identify customer segments with highest churn risk.\"\"\"\n",
    "        trace_id = self._trace_operation(\"identify_high_risk_segments\")\n",
    "        \n",
    "        try:\n",
    "            segments = self.df.groupby(['Geography', 'Gender', 'IsActiveMember'], observed=True).agg({\n",
    "                'Exited': ['sum', 'count', 'mean'],\n",
    "                'Balance': 'mean',\n",
    "                'Age': 'mean'\n",
    "            }).round(2)\n",
    "            segments.columns = ['Churned', 'Total', 'Churn_Rate', 'Avg_Balance', 'Avg_Age']\n",
    "            segments['Churn_Rate'] = segments['Churn_Rate'] * 100\n",
    "            high_risk = segments[segments['Total'] >= 50].sort_values('Churn_Rate', ascending=False)\n",
    "            self.insights['high_risk_segments'] = high_risk.head(10)\n",
    "            \n",
    "            self._log(\"info\", f\"High-risk segment analysis complete: {len(high_risk)} segments identified\", trace_id)\n",
    "            self._end_trace(trace_id, \"success\")\n",
    "            return high_risk.head(10)\n",
    "        except Exception as e:\n",
    "            self._log(\"error\", f\"High-risk segment analysis failed: {str(e)}\", trace_id)\n",
    "            self._end_trace(trace_id, \"error\")\n",
    "            raise\n",
    "    \n",
    "    def analyze_financial_profile(self) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze financial characteristics of churned vs retained customers.\"\"\"\n",
    "        trace_id = self._trace_operation(\"analyze_financial_profile\")\n",
    "        \n",
    "        try:\n",
    "            churned = self.df[self.df['Exited'] == 1]\n",
    "            retained = self.df[self.df['Exited'] == 0]\n",
    "            \n",
    "            financial_profile = {\n",
    "                'churned_customers': {\n",
    "                    'avg_balance': float(churned['Balance'].mean()),\n",
    "                    'median_balance': float(churned['Balance'].median()),\n",
    "                    'avg_credit_score': float(churned['CreditScore'].mean()),\n",
    "                    'avg_salary': float(churned['EstimatedSalary'].mean()),\n",
    "                    'zero_balance_pct': float((churned['Balance'] == 0).sum() / len(churned) * 100)\n",
    "                },\n",
    "                'retained_customers': {\n",
    "                    'avg_balance': float(retained['Balance'].mean()),\n",
    "                    'median_balance': float(retained['Balance'].median()),\n",
    "                    'avg_credit_score': float(retained['CreditScore'].mean()),\n",
    "                    'avg_salary': float(retained['EstimatedSalary'].mean()),\n",
    "                    'zero_balance_pct': float((retained['Balance'] == 0).sum() / len(retained) * 100)\n",
    "                }\n",
    "            }\n",
    "            self.insights['financial_profile'] = financial_profile\n",
    "            \n",
    "            self._log(\"info\", \"Financial profile analysis complete\", trace_id)\n",
    "            self._end_trace(trace_id, \"success\")\n",
    "            return financial_profile\n",
    "        except Exception as e:\n",
    "            self._log(\"error\", f\"Financial profile analysis failed: {str(e)}\", trace_id)\n",
    "            self._end_trace(trace_id, \"error\")\n",
    "            raise\n",
    "    \n",
    "    def calculate_customer_lifetime_value_impact(self) -> Dict[str, float]:\n",
    "        \"\"\"Calculate the financial impact of customer churn.\"\"\"\n",
    "        trace_id = self._trace_operation(\"calculate_clv_impact\")\n",
    "        \n",
    "        try:\n",
    "            churned = self.df[self.df['Exited'] == 1]\n",
    "            estimated_revenue_per_customer = 0.01\n",
    "            \n",
    "            impact = {\n",
    "                'total_churned_customers': int(len(churned)),\n",
    "                'total_balance_lost': float(churned['Balance'].sum()),\n",
    "                'avg_balance_per_churned_customer': float(churned['Balance'].mean()),\n",
    "                'estimated_annual_revenue_loss': float(churned['Balance'].sum() * estimated_revenue_per_customer),\n",
    "                'avg_tenure_of_churned': float(churned['Tenure'].mean()),\n",
    "            }\n",
    "            self.insights['clv_impact'] = impact\n",
    "            \n",
    "            self._log(\"info\", f\"CLV impact calculated: ${impact['estimated_annual_revenue_loss']:,.2f} estimated revenue loss\", trace_id)\n",
    "            self._end_trace(trace_id, \"success\")\n",
    "            return impact\n",
    "        except Exception as e:\n",
    "            self._log(\"error\", f\"CLV impact calculation failed: {str(e)}\", trace_id)\n",
    "            self._end_trace(trace_id, \"error\")\n",
    "            raise\n",
    "    \n",
    "    def get_all_insights(self) -> Dict[str, Any]:\n",
    "        \"\"\"Run all analyses and return comprehensive insights dictionary.\"\"\"\n",
    "        trace_id = self._trace_operation(\"get_all_insights\")\n",
    "        \n",
    "        try:\n",
    "            self.generate_executive_summary()\n",
    "            self.analyze_churn_by_geography()\n",
    "            self.analyze_churn_by_demographics()\n",
    "            self.analyze_product_engagement()\n",
    "            self.identify_high_risk_segments()\n",
    "            self.analyze_financial_profile()\n",
    "            self.calculate_customer_lifetime_value_impact()\n",
    "            \n",
    "            self._log(\"info\", \"All insights generated successfully\", trace_id)\n",
    "            self._end_trace(trace_id, \"success\")\n",
    "            return self.insights\n",
    "        except Exception as e:\n",
    "            self._log(\"error\", f\"Failed to generate all insights: {str(e)}\", trace_id)\n",
    "            self._end_trace(trace_id, \"error\")\n",
    "            raise\n",
    "    \n",
    "    # ============================================================================\n",
    "    # GEMINI-POWERED Q&A FUNCTIONALITY\n",
    "    # ============================================================================\n",
    "    \n",
    "    def _prepare_context(self) -> str:\n",
    "        \"\"\"\n",
    "        Prepare a comprehensive context string with all insights for Gemini.\n",
    "        \"\"\"\n",
    "        if not self.insights:\n",
    "            self.get_all_insights()\n",
    "        \n",
    "        context = \"=== BANK CUSTOMER CHURN ANALYSIS DATA ===\\n\\n\"\n",
    "        \n",
    "        # Executive Summary\n",
    "        context += \"EXECUTIVE SUMMARY:\\n\"\n",
    "        for key, value in self.insights['executive_summary'].items():\n",
    "            context += f\"- {key.replace('_', ' ').title()}: {value:,.2f}\\n\"\n",
    "        \n",
    "        # Geography Analysis\n",
    "        context += \"\\nCHURN BY GEOGRAPHY:\\n\"\n",
    "        geo_df = self.insights['geography_analysis']\n",
    "        for geo, row in geo_df.iterrows():\n",
    "            context += f\"- {geo}: {row['Churn_Rate']:.2f}% churn rate, \"\n",
    "            context += f\"{int(row['Churned_Customers'])} of {int(row['Total_Customers'])} customers, \"\n",
    "            context += f\"Avg Balance: ${row['Avg_Balance']:,.2f}\\n\"\n",
    "        \n",
    "        # Demographics - Age\n",
    "        context += \"\\nCHURN BY AGE GROUP:\\n\"\n",
    "        age_df = self.insights['demographics']['age_analysis']\n",
    "        for age_group, row in age_df.iterrows():\n",
    "            context += f\"- {age_group}: {row['Churn_Rate']:.2f}% churn rate, \"\n",
    "            context += f\"{int(row['Churned'])} of {int(row['Total'])} customers\\n\"\n",
    "        \n",
    "        # Demographics - Gender\n",
    "        context += \"\\nCHURN BY GENDER:\\n\"\n",
    "        gender_df = self.insights['demographics']['gender_analysis']\n",
    "        for gender, row in gender_df.iterrows():\n",
    "            context += f\"- {gender}: {row['Churn_Rate']:.2f}% churn rate, \"\n",
    "            context += f\"{int(row['Churned'])} of {int(row['Total'])} customers\\n\"\n",
    "        \n",
    "        # Product Engagement\n",
    "        context += \"\\nCHURN BY NUMBER OF PRODUCTS:\\n\"\n",
    "        product_df = self.insights['product_engagement']\n",
    "        for num_products, row in product_df.iterrows():\n",
    "            context += f\"- {int(num_products)} products: {row['Churn_Rate']:.2f}% churn rate, \"\n",
    "            context += f\"{int(row['Churned'])} of {int(row['Total'])} customers, \"\n",
    "            context += f\"Avg Tenure: {row['Avg_Tenure']:.1f} years, \"\n",
    "            context += f\"Active Rate: {row['Active_Rate']:.1f}%\\n\"\n",
    "        \n",
    "        # High Risk Segments\n",
    "        context += \"\\nTOP 5 HIGH-RISK SEGMENTS:\\n\"\n",
    "        high_risk = self.insights['high_risk_segments'].head(5)\n",
    "        for idx, (segment, row) in enumerate(high_risk.iterrows(), 1):\n",
    "            geo, gender, is_active = segment\n",
    "            active_status = \"Active\" if is_active == 1 else \"Inactive\"\n",
    "            context += f\"{idx}. {geo} - {gender} - {active_status}: \"\n",
    "            context += f\"{row['Churn_Rate']:.2f}% churn rate, {int(row['Total'])} customers\\n\"\n",
    "        \n",
    "        # Financial Profile\n",
    "        context += \"\\nFINANCIAL PROFILE COMPARISON:\\n\"\n",
    "        fp = self.insights['financial_profile']\n",
    "        context += \"Churned Customers:\\n\"\n",
    "        context += f\"  - Avg Balance: ${fp['churned_customers']['avg_balance']:,.2f}\\n\"\n",
    "        context += f\"  - Avg Credit Score: {fp['churned_customers']['avg_credit_score']:.0f}\\n\"\n",
    "        context += f\"  - Avg Salary: ${fp['churned_customers']['avg_salary']:,.2f}\\n\"\n",
    "        context += \"Retained Customers:\\n\"\n",
    "        context += f\"  - Avg Balance: ${fp['retained_customers']['avg_balance']:,.2f}\\n\"\n",
    "        context += f\"  - Avg Credit Score: {fp['retained_customers']['avg_credit_score']:.0f}\\n\"\n",
    "        context += f\"  - Avg Salary: ${fp['retained_customers']['avg_salary']:,.2f}\\n\"\n",
    "        \n",
    "        # Financial Impact\n",
    "        context += \"\\nFINANCIAL IMPACT:\\n\"\n",
    "        impact = self.insights['clv_impact']\n",
    "        context += f\"- Total Churned Customers: {impact['total_churned_customers']:,}\\n\"\n",
    "        context += f\"- Total Balance Lost: ${impact['total_balance_lost']:,.2f}\\n\"\n",
    "        context += f\"- Estimated Annual Revenue Loss: ${impact['estimated_annual_revenue_loss']:,.2f}\\n\"\n",
    "        context += f\"- Avg Tenure of Churned: {impact['avg_tenure_of_churned']:.1f} years\\n\"\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    def _create_system_prompt(self) -> str:\n",
    "        \"\"\"\n",
    "        Create the system prompt that defines the agent's role and behavior.\n",
    "        \"\"\"\n",
    "        system_prompt = \"\"\"You are an expert Analytics Agent specializing in customer churn analysis for a bank. \n",
    "\n",
    "                        Your role is to answer executive questions about customer churn data with:\n",
    "                        - Clear, concise, and actionable insights\n",
    "                        - Data-driven responses based on the provided analysis\n",
    "                        - Executive-friendly language (avoid jargon)\n",
    "                        - Specific numbers and percentages from the data\n",
    "                        - Strategic recommendations when appropriate\n",
    "                        - Professional formatting with emojis for visual clarity (üìä üåç üë• üí∞ ‚ö†Ô∏è üéØ)\n",
    "                        - Make sure you are not using any jargon or complicated words, keep the wording very simple and clear\n",
    "                        - If you are asked a question beyond the scope of the dataset make sure to mention that you can only answer questions based on the customer churn data\n",
    "                        \n",
    "                        When answering:\n",
    "                        1. Always reference specific data points from the analysis\n",
    "                        2. Highlight key insights and patterns\n",
    "                        3. Provide context and comparisons\n",
    "                        4. End with actionable recommendations when relevant\n",
    "                        5. Be direct and avoid unnecessary preamble\n",
    "                        6. Use bullet points and clear structure\n",
    "                        7. If asked a question beyond the scope of the dataset, mention that this question is out of scope\n",
    "                        \n",
    "                        The data context below contains all the churn analysis results you should reference. \n",
    "                        \"\"\"\n",
    "        return system_prompt\n",
    "    \n",
    "    def model_config(self, system_prompt: str, user_prompt: str) -> str:\n",
    "        \"\"\"\n",
    "        Configure and call Gemini model with the given prompts.\n",
    "        \n",
    "        Args:\n",
    "            system_prompt: System instructions for the model\n",
    "            user_prompt: User's question\n",
    "            \n",
    "        Returns:\n",
    "            Model's response text\n",
    "        \"\"\"\n",
    "        try:\n",
    "            api_key = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "        except Exception:\n",
    "            return \"[Simulated LLM: GOOGLE_API_KEY secret not accessible in this environment.]\"\n",
    "        \n",
    "        try:    \n",
    "            gen.configure(api_key=api_key)\n",
    "            model = gen.GenerativeModel(\"gemini-2.0-flash-exp\")\n",
    "            prompt = system_prompt + \"\\n\\n\" + user_prompt\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"[Simulated LLM: Gemini unreachable ‚Üí {e}]\"\n",
    "    \n",
    "    def ask(self, question: str) -> str:\n",
    "        \"\"\"\n",
    "        Main Q&A interface. Ask the agent any question about the churn data.\n",
    "        Powered by Google Gemini LLM.\n",
    "        \n",
    "        Now with full observability: logging, tracing, and metrics collection.\n",
    "        \n",
    "        Args:\n",
    "            question: Natural language question from the executive\n",
    "            \n",
    "        Returns:\n",
    "            String answer to the question\n",
    "        \"\"\"\n",
    "        # Start tracing for this request\n",
    "        trace_id = self._trace_operation(\"ask_question\", {\"question\": question[:100]})\n",
    "        start_time = time.time()\n",
    "        success = True\n",
    "        tool_used = \"ask\"\n",
    "        \n",
    "        try:\n",
    "            # Ensure insights are generated\n",
    "            if not self.insights:\n",
    "                self._log(\"info\", \"Generating insights for first question...\", trace_id)\n",
    "                print(\"üìä Analyzing data... Please wait...\")\n",
    "                self.get_all_insights()\n",
    "                print(\"‚úÖ Analysis complete!\\n\")\n",
    "            \n",
    "            # Determine which tool/analysis area is being used based on question\n",
    "            question_lower = question.lower()\n",
    "            if any(word in question_lower for word in ['geography', 'country', 'region', 'location']):\n",
    "                tool_used = \"geography_analysis\"\n",
    "            elif any(word in question_lower for word in ['age', 'gender', 'demographic']):\n",
    "                tool_used = \"demographics_analysis\"\n",
    "            elif any(word in question_lower for word in ['product', 'engagement', 'active']):\n",
    "                tool_used = \"product_analysis\"\n",
    "            elif any(word in question_lower for word in ['risk', 'segment', 'high-risk']):\n",
    "                tool_used = \"risk_analysis\"\n",
    "            elif any(word in question_lower for word in ['financial', 'balance', 'revenue', 'impact', 'money']):\n",
    "                tool_used = \"financial_analysis\"\n",
    "            \n",
    "            self._log(\"debug\", f\"Question classified as: {tool_used}\", trace_id)\n",
    "            \n",
    "            # Store question in chat history\n",
    "            self.chat_history.append({'role': 'user', 'content': question})\n",
    "            \n",
    "            # Prepare context and prompts\n",
    "            self._log(\"debug\", \"Preparing context for LLM...\", trace_id)\n",
    "            context = self._prepare_context()\n",
    "            system_prompt = self._create_system_prompt()\n",
    "            user_prompt = f\"DATA CONTEXT:\\n{context}\\n\\nEXECUTIVE QUESTION:\\n{question}\\n\\nProvide a clear, data-driven answer:\"\n",
    "            \n",
    "            # Get response from Gemini\n",
    "            self._log(\"info\", \"Sending request to Gemini LLM...\", trace_id)\n",
    "            llm_start = time.time()\n",
    "            answer = self.model_config(system_prompt, user_prompt)\n",
    "            llm_duration = time.time() - llm_start\n",
    "            \n",
    "            if self.observability:\n",
    "                self.observability.add_span(trace_id, \"llm_call\", llm_duration * 1000, \"success\")\n",
    "            \n",
    "            # Store answer in chat history\n",
    "            self.chat_history.append({'role': 'agent', 'content': answer})\n",
    "            \n",
    "            self._log(\"info\", f\"Response generated successfully ({llm_duration:.2f}s)\", trace_id)\n",
    "            \n",
    "            return answer\n",
    "            \n",
    "        except Exception as e:\n",
    "            success = False\n",
    "            self._log(\"error\", f\"Error processing question: {str(e)}\", trace_id)\n",
    "            raise\n",
    "            \n",
    "        finally:\n",
    "            # Record metrics for this request\n",
    "            response_time = time.time() - start_time\n",
    "            if self.observability:\n",
    "                self.observability.record_request(response_time, tool_used, success)\n",
    "            self._end_trace(trace_id, \"success\" if success else \"error\")\n",
    "    \n",
    "    def start_chat(self):\n",
    "        \"\"\"\n",
    "        Start an interactive chat session (for Jupyter notebooks or console).\n",
    "        Type 'quit', 'exit', or 'bye' to end the session.\n",
    "        \"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"ü§ñ ANALYTICS AGENT - EXECUTIVE Q&A SESSION (Powered by Gemini)\")\n",
    "        print(\"=\" * 80)\n",
    "        print(\"\\nHello! I'm your AI-powered Analytics Agent. I can answer questions about\")\n",
    "        print(\"customer churn using advanced language understanding.\")\n",
    "        print(\"\\nType 'quit', 'exit', or 'bye' to end the session.\")\n",
    "        print(\"Type 'metrics' to see observability metrics.\\n\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Ensure insights are loaded\n",
    "        if not self.insights:\n",
    "            print(\"üìä Loading and analyzing data... Please wait...\")\n",
    "            self.get_all_insights()\n",
    "            print(\"‚úÖ Ready to answer your questions!\\n\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                question = input(\"\\nüíº Executive: \").strip()\n",
    "                \n",
    "                if question.lower() in ['quit', 'exit', 'bye', 'q']:\n",
    "                    print(\"\\nüëã Thank you for using Analytics Agent. Goodbye!\")\n",
    "                    if self.observability:\n",
    "                        self.observability.print_metrics_report()\n",
    "                    break\n",
    "                \n",
    "                if question.lower() == 'metrics':\n",
    "                    if self.observability:\n",
    "                        self.observability.print_metrics_report()\n",
    "                    else:\n",
    "                        print(\"Observability is not enabled.\")\n",
    "                    continue\n",
    "                \n",
    "                if not question:\n",
    "                    continue\n",
    "                \n",
    "                print(\"\\nü§ñ Agent: [Thinking...]\\n\")\n",
    "                answer = self.ask(question)\n",
    "                print(answer)\n",
    "                print(\"\\n\" + \"-\" * 80)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n\\nüëã Session ended. Goodbye!\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"\\n‚ùå Error: {str(e)}\")\n",
    "                print(\"Please try rephrasing your question.\\n\")\n",
    "    \n",
    "    def get_chat_history(self) -> List[Dict[str, str]]:\n",
    "        \"\"\"Return the chat history.\"\"\"\n",
    "        return self.chat_history\n",
    "    \n",
    "    def clear_chat_history(self):\n",
    "        \"\"\"Clear the chat history.\"\"\"\n",
    "        self.chat_history = []\n",
    "        self._log(\"info\", \"Chat history cleared\")\n",
    "        print(\"‚úÖ Chat history cleared.\")\n",
    "    \n",
    "    def print_executive_report(self):\n",
    "        \"\"\"Print a formatted executive report to console.\"\"\"\n",
    "        trace_id = self._trace_operation(\"print_executive_report\")\n",
    "        \n",
    "        insights = self.get_all_insights()\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"EXECUTIVE INSIGHTS REPORT - BANK CUSTOMER CHURN ANALYSIS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        print(\"\\nüìà EXECUTIVE SUMMARY:\")\n",
    "        print(\"-\" * 80)\n",
    "        for key, value in insights['executive_summary'].items():\n",
    "            key_formatted = key.replace('_', ' ').title()\n",
    "            if isinstance(value, int):\n",
    "                print(f\"  {key_formatted}: {value:,}\")\n",
    "            else:\n",
    "                print(f\"  {key_formatted}: {value:,.2f}\")\n",
    "        \n",
    "        print(\"\\n\\nüåç CHURN BY GEOGRAPHY:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(insights['geography_analysis'])\n",
    "        \n",
    "        print(\"\\n\\nüì¶ PRODUCT ENGAGEMENT:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(insights['product_engagement'])\n",
    "        \n",
    "        print(\"\\n\\n‚ö†Ô∏è  TOP 5 HIGH-RISK SEGMENTS:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(insights['high_risk_segments'].head())\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        \n",
    "        self._end_trace(trace_id, \"success\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # OBSERVABILITY METHODS\n",
    "    # ============================================================================\n",
    "    \n",
    "    def get_observability_metrics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get current observability metrics.\"\"\"\n",
    "        if self.observability:\n",
    "            return self.observability.get_metrics_summary()\n",
    "        return {\"error\": \"Observability not enabled\"}\n",
    "    \n",
    "    def print_observability_report(self):\n",
    "        \"\"\"Print the observability metrics report.\"\"\"\n",
    "        if self.observability:\n",
    "            self.observability.print_metrics_report()\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Observability is not enabled for this agent.\")\n",
    "    \n",
    "    def get_recent_traces(self, n: int = 5) -> List[Dict]:\n",
    "        \"\"\"Get recent traces for debugging.\"\"\"\n",
    "        if self.observability:\n",
    "            return self.observability.get_recent_traces(n)\n",
    "        return []\n",
    "\n",
    "print(\"‚úÖ AnalyticsAgent class loaded successfully with observability!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T19:18:19.209366Z",
     "iopub.status.busy": "2025-11-30T19:18:19.208862Z",
     "iopub.status.idle": "2025-11-30T19:18:19.216472Z",
     "shell.execute_reply": "2025-11-30T19:18:19.215487Z",
     "shell.execute_reply.started": "2025-11-30T19:18:19.209337Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent initialized and ready!\n"
     ]
    }
   ],
   "source": [
    "# Create the Analytics Agent\n",
    "agent = AnalyticsAgent(df)\n",
    "\n",
    "print(\"‚úÖ Agent initialized and ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OBSERVABILITY DASHBOARD\n",
    "# =============================================================================\n",
    "# This cell provides a visual dashboard for monitoring agent performance\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "class ObservabilityDashboard:\n",
    "    \"\"\"\n",
    "    Interactive dashboard for monitoring agent observability metrics.\n",
    "    \n",
    "    Features:\n",
    "    - Real-time metrics display\n",
    "    - Trace viewer for debugging\n",
    "    - Performance charts\n",
    "    - Error analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, agent: AnalyticsAgent):\n",
    "        \"\"\"\n",
    "        Initialize the dashboard with an agent.\n",
    "        \n",
    "        Args:\n",
    "            agent: AnalyticsAgent instance with observability enabled\n",
    "        \"\"\"\n",
    "        self.agent = agent\n",
    "        self.create_widgets()\n",
    "    \n",
    "    def create_widgets(self):\n",
    "        \"\"\"Create dashboard widgets.\"\"\"\n",
    "        # Metrics output area\n",
    "        self.metrics_output = widgets.Output(\n",
    "            layout=widgets.Layout(\n",
    "                min_height='200px',\n",
    "                border='2px solid #4CAF50',\n",
    "                padding='15px',\n",
    "                margin='10px 0',\n",
    "                border_radius='8px'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Traces output area\n",
    "        self.traces_output = widgets.Output(\n",
    "            layout=widgets.Layout(\n",
    "                min_height='200px',\n",
    "                border='2px solid #2196F3',\n",
    "                padding='15px',\n",
    "                margin='10px 0',\n",
    "                border_radius='8px'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Refresh button\n",
    "        self.refresh_button = widgets.Button(\n",
    "            description='üîÑ Refresh Metrics',\n",
    "            button_style='success',\n",
    "            layout=widgets.Layout(width='200px', margin='10px 5px')\n",
    "        )\n",
    "        self.refresh_button.on_click(self.refresh_metrics)\n",
    "        \n",
    "        # Clear traces button\n",
    "        self.clear_traces_button = widgets.Button(\n",
    "            description='üóëÔ∏è Clear History',\n",
    "            button_style='warning',\n",
    "            layout=widgets.Layout(width='200px', margin='10px 5px')\n",
    "        )\n",
    "        self.clear_traces_button.on_click(self.clear_traces)\n",
    "        \n",
    "        # Trace count selector\n",
    "        self.trace_count = widgets.IntSlider(\n",
    "            value=5,\n",
    "            min=1,\n",
    "            max=20,\n",
    "            step=1,\n",
    "            description='Traces:',\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "        self.trace_count.observe(self.on_trace_count_change, names='value')\n",
    "    \n",
    "    def refresh_metrics(self, b=None):\n",
    "        \"\"\"Refresh the metrics display.\"\"\"\n",
    "        self.metrics_output.clear_output()\n",
    "        \n",
    "        with self.metrics_output:\n",
    "            if not self.agent.observability:\n",
    "                display(HTML(\"\"\"\n",
    "                <div style=\"color: #FF5722; padding: 20px; text-align: center;\">\n",
    "                    <h3>‚ö†Ô∏è Observability Not Enabled</h3>\n",
    "                    <p>Create agent with: <code>AnalyticsAgent(df, enable_observability=True)</code></p>\n",
    "                </div>\n",
    "                \"\"\"))\n",
    "                return\n",
    "            \n",
    "            metrics = self.agent.get_observability_metrics()\n",
    "            \n",
    "            # Create metrics cards\n",
    "            html_content = f\"\"\"\n",
    "            <div style=\"font-family: Arial, sans-serif;\">\n",
    "                <h2 style=\"color: #333; border-bottom: 2px solid #4CAF50; padding-bottom: 10px;\">\n",
    "                    üìä Agent Observability Metrics\n",
    "                </h2>\n",
    "                \n",
    "                <div style=\"display: flex; flex-wrap: wrap; gap: 15px; margin-top: 15px;\">\n",
    "                    <!-- Total Requests Card -->\n",
    "                    <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
    "                                color: white; padding: 20px; border-radius: 10px; min-width: 150px; text-align: center;\">\n",
    "                        <div style=\"font-size: 32px; font-weight: bold;\">{metrics['total_requests']}</div>\n",
    "                        <div style=\"font-size: 14px; opacity: 0.9;\">Total Requests</div>\n",
    "                    </div>\n",
    "                    \n",
    "                    <!-- Success Rate Card -->\n",
    "                    <div style=\"background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); \n",
    "                                color: white; padding: 20px; border-radius: 10px; min-width: 150px; text-align: center;\">\n",
    "                        <div style=\"font-size: 32px; font-weight: bold;\">{metrics['success_rate']:.1f}%</div>\n",
    "                        <div style=\"font-size: 14px; opacity: 0.9;\">Success Rate</div>\n",
    "                    </div>\n",
    "                    \n",
    "                    <!-- Avg Response Time Card -->\n",
    "                    <div style=\"background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); \n",
    "                                color: white; padding: 20px; border-radius: 10px; min-width: 150px; text-align: center;\">\n",
    "                        <div style=\"font-size: 32px; font-weight: bold;\">{metrics['avg_response_time_sec']:.2f}s</div>\n",
    "                        <div style=\"font-size: 14px; opacity: 0.9;\">Avg Response Time</div>\n",
    "                    </div>\n",
    "                    \n",
    "                    <!-- Errors Card -->\n",
    "                    <div style=\"background: linear-gradient(135deg, #ff416c 0%, #ff4b2b 100%); \n",
    "                                color: white; padding: 20px; border-radius: 10px; min-width: 150px; text-align: center;\">\n",
    "                        <div style=\"font-size: 32px; font-weight: bold;\">{metrics['total_errors']}</div>\n",
    "                        <div style=\"font-size: 14px; opacity: 0.9;\">Total Errors</div>\n",
    "                    </div>\n",
    "                </div>\n",
    "                \n",
    "                <!-- Requests by Tool -->\n",
    "                <div style=\"margin-top: 20px; background: #f5f5f5; padding: 15px; border-radius: 8px;\">\n",
    "                    <h3 style=\"color: #333; margin-top: 0;\">üìà Requests by Analysis Type</h3>\n",
    "                    <table style=\"width: 100%; border-collapse: collapse;\">\n",
    "                        <tr style=\"background: #e0e0e0;\">\n",
    "                            <th style=\"padding: 10px; text-align: left; border-radius: 5px 0 0 0;\">Analysis Type</th>\n",
    "                            <th style=\"padding: 10px; text-align: right; border-radius: 0 5px 0 0;\">Count</th>\n",
    "                        </tr>\n",
    "            \"\"\"\n",
    "            \n",
    "            for tool, count in metrics['requests_per_tool'].items():\n",
    "                bar_width = min(count * 20, 100)\n",
    "                html_content += f\"\"\"\n",
    "                        <tr>\n",
    "                            <td style=\"padding: 10px; border-bottom: 1px solid #ddd;\">\n",
    "                                {tool.replace('_', ' ').title()}\n",
    "                            </td>\n",
    "                            <td style=\"padding: 10px; border-bottom: 1px solid #ddd; text-align: right;\">\n",
    "                                <div style=\"display: flex; align-items: center; justify-content: flex-end;\">\n",
    "                                    <div style=\"background: #667eea; height: 20px; width: {bar_width}px; \n",
    "                                                border-radius: 3px; margin-right: 10px;\"></div>\n",
    "                                    <strong>{count}</strong>\n",
    "                                </div>\n",
    "                            </td>\n",
    "                        </tr>\n",
    "                \"\"\"\n",
    "            \n",
    "            html_content += \"\"\"\n",
    "                    </table>\n",
    "                </div>\n",
    "            \"\"\"\n",
    "            \n",
    "            # Error breakdown if any errors\n",
    "            if metrics['errors_by_type']:\n",
    "                html_content += \"\"\"\n",
    "                <div style=\"margin-top: 20px; background: #ffebee; padding: 15px; border-radius: 8px; border-left: 4px solid #f44336;\">\n",
    "                    <h3 style=\"color: #c62828; margin-top: 0;\">‚ö†Ô∏è Errors by Type</h3>\n",
    "                    <ul style=\"margin: 0; padding-left: 20px;\">\n",
    "                \"\"\"\n",
    "                for error_type, count in metrics['errors_by_type'].items():\n",
    "                    html_content += f\"<li style='color: #333;'><strong>{error_type}</strong>: {count}</li>\"\n",
    "                html_content += \"</ul></div>\"\n",
    "            \n",
    "            html_content += \"</div>\"\n",
    "            \n",
    "            display(HTML(html_content))\n",
    "    \n",
    "    def refresh_traces(self, n: int = 5):\n",
    "        \"\"\"Refresh the traces display.\"\"\"\n",
    "        self.traces_output.clear_output()\n",
    "        \n",
    "        with self.traces_output:\n",
    "            if not self.agent.observability:\n",
    "                display(HTML(\"<p style='color: #FF5722;'>‚ö†Ô∏è Observability not enabled</p>\"))\n",
    "                return\n",
    "            \n",
    "            traces = self.agent.get_recent_traces(n)\n",
    "            \n",
    "            if not traces:\n",
    "                display(HTML(\"\"\"\n",
    "                <div style=\"text-align: center; padding: 30px; color: #666;\">\n",
    "                    <h3>üìã No Traces Yet</h3>\n",
    "                    <p>Ask the agent some questions to see traces here.</p>\n",
    "                </div>\n",
    "                \"\"\"))\n",
    "                return\n",
    "            \n",
    "            html_content = \"\"\"\n",
    "            <div style=\"font-family: Arial, sans-serif;\">\n",
    "                <h2 style=\"color: #333; border-bottom: 2px solid #2196F3; padding-bottom: 10px;\">\n",
    "                    üîç Recent Traces\n",
    "                </h2>\n",
    "            \"\"\"\n",
    "            \n",
    "            for trace in reversed(traces):\n",
    "                status_color = \"#4CAF50\" if trace['status'] == 'success' else \"#f44336\"\n",
    "                status_icon = \"‚úÖ\" if trace['status'] == 'success' else \"‚ùå\"\n",
    "                duration = f\"{trace['duration_ms']:.2f}ms\" if trace['duration_ms'] else \"In Progress\"\n",
    "                \n",
    "                html_content += f\"\"\"\n",
    "                <div style=\"background: #fff; border: 1px solid #ddd; border-radius: 8px; \n",
    "                            padding: 15px; margin: 10px 0; border-left: 4px solid {status_color};\">\n",
    "                    <div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
    "                        <div>\n",
    "                            <strong style=\"color: #333; font-size: 16px;\">{status_icon} {trace['operation']}</strong>\n",
    "                            <span style=\"color: #666; font-size: 12px; margin-left: 10px;\">\n",
    "                                Trace ID: {trace['trace_id']}\n",
    "                            </span>\n",
    "                        </div>\n",
    "                        <div style=\"text-align: right;\">\n",
    "                            <span style=\"background: #e3f2fd; color: #1565c0; padding: 3px 8px; \n",
    "                                        border-radius: 4px; font-size: 12px;\">{duration}</span>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                    <div style=\"font-size: 12px; color: #666; margin-top: 8px;\">\n",
    "                        Started: {trace['start_time'].strftime('%H:%M:%S') if trace['start_time'] else 'N/A'}\n",
    "                    </div>\n",
    "                \"\"\"\n",
    "                \n",
    "                # Show spans if any\n",
    "                if trace.get('spans'):\n",
    "                    html_content += \"\"\"\n",
    "                    <div style=\"margin-top: 10px; padding-left: 15px; border-left: 2px solid #e0e0e0;\">\n",
    "                        <div style=\"font-size: 12px; color: #666; font-weight: bold;\">Spans:</div>\n",
    "                    \"\"\"\n",
    "                    for span in trace['spans']:\n",
    "                        span_color = \"#4CAF50\" if span['status'] == 'success' else \"#f44336\"\n",
    "                        html_content += f\"\"\"\n",
    "                        <div style=\"font-size: 11px; color: #555; margin: 3px 0;\">\n",
    "                            <span style=\"color: {span_color};\">‚óè</span> {span['name']}: {span['duration_ms']:.2f}ms\n",
    "                        </div>\n",
    "                        \"\"\"\n",
    "                    html_content += \"</div>\"\n",
    "                \n",
    "                # Show metadata if any\n",
    "                if trace.get('metadata'):\n",
    "                    html_content += f\"\"\"\n",
    "                    <div style=\"margin-top: 8px; font-size: 11px; color: #888; \n",
    "                                background: #f5f5f5; padding: 5px 10px; border-radius: 4px;\">\n",
    "                        Metadata: {str(trace['metadata'])[:100]}...\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "                \n",
    "                html_content += \"</div>\"\n",
    "            \n",
    "            html_content += \"</div>\"\n",
    "            display(HTML(html_content))\n",
    "    \n",
    "    def on_trace_count_change(self, change):\n",
    "        \"\"\"Handle trace count slider change.\"\"\"\n",
    "        self.refresh_traces(change['new'])\n",
    "    \n",
    "    def clear_traces(self, b=None):\n",
    "        \"\"\"Clear trace history display.\"\"\"\n",
    "        self.traces_output.clear_output()\n",
    "        with self.traces_output:\n",
    "            display(HTML(\"\"\"\n",
    "            <div style=\"text-align: center; padding: 30px; color: #666;\">\n",
    "                <h3>üìã Traces Cleared</h3>\n",
    "                <p>New traces will appear here as you interact with the agent.</p>\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the full dashboard.\"\"\"\n",
    "        # Header\n",
    "        header = widgets.HTML(\"\"\"\n",
    "        <div style=\"background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); \n",
    "                    color: white; padding: 20px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "            <h1 style=\"margin: 0; color: white;\">üîç Agent Observability Dashboard</h1>\n",
    "            <p style=\"margin: 10px 0 0 0; opacity: 0.8; color: #ccc;\">\n",
    "                Monitor logging, tracing, and metrics for your AI Analytics Agent\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        \n",
    "        # Button row\n",
    "        buttons = widgets.HBox([\n",
    "            self.refresh_button,\n",
    "            self.clear_traces_button,\n",
    "            self.trace_count\n",
    "        ])\n",
    "        \n",
    "        # Tabs for metrics and traces\n",
    "        tab = widgets.Tab()\n",
    "        tab.children = [self.metrics_output, self.traces_output]\n",
    "        tab.set_title(0, 'üìä Metrics')\n",
    "        tab.set_title(1, 'üîç Traces')\n",
    "        \n",
    "        # Layout\n",
    "        dashboard = widgets.VBox([\n",
    "            header,\n",
    "            buttons,\n",
    "            tab\n",
    "        ])\n",
    "        \n",
    "        # Initial refresh\n",
    "        self.refresh_metrics()\n",
    "        self.refresh_traces()\n",
    "        \n",
    "        display(dashboard)\n",
    "\n",
    "\n",
    "def create_observability_dashboard(agent: AnalyticsAgent):\n",
    "    \"\"\"\n",
    "    Create and display an observability dashboard for the agent.\n",
    "    \n",
    "    Args:\n",
    "        agent: AnalyticsAgent instance with observability enabled\n",
    "        \n",
    "    Returns:\n",
    "        ObservabilityDashboard instance\n",
    "    \"\"\"\n",
    "    dashboard = ObservabilityDashboard(agent)\n",
    "    dashboard.display()\n",
    "    return dashboard\n",
    "\n",
    "print(\"‚úÖ Observability Dashboard loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Using the Observability Dashboard\n",
    "\n",
    "The dashboard provides real-time monitoring of your AI Agent:\n",
    "\n",
    "| Tab | Description |\n",
    "|-----|-------------|\n",
    "| **Metrics** | View total requests, success rates, response times, and error counts |\n",
    "| **Traces** | Debug individual operations with unique trace IDs and timing spans |\n",
    "\n",
    "**To use:** Run the cell below after asking the agent some questions to see metrics populate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Observability Dashboard\n",
    "# Note: Run this after asking some questions to the agent to see metrics\n",
    "dashboard = create_observability_dashboard(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T19:18:20.927050Z",
     "iopub.status.busy": "2025-11-30T19:18:20.926759Z",
     "iopub.status.idle": "2025-11-30T19:18:22.842641Z",
     "shell.execute_reply": "2025-11-30T19:18:22.841659Z",
     "shell.execute_reply.started": "2025-11-30T19:18:20.927030Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Analyzing data... Please wait...\n",
      "‚úÖ Analysis complete!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I can help you understand why customers are leaving the bank and what actions can be taken to keep them. \\n\\nI can support you with this customer churn data, which includes:\\n\\n*   **Customer Demographics:** Age, gender, and location (France, Germany, Spain). üåç\\n*   **Account Information:** Account balance, number of products, credit card ownership, and active member status. üí∞\\n*   **Churn Status:** Whether a customer has left the bank or not. ‚ö†Ô∏è\\n*   **Financial Details:** Credit score and estimated salary. üìä\\n*   **Tenure:** How long a customer has been with the bank. üë•\\n\\nUsing this data, I can identify trends, high-risk groups, and potential areas for improvement to reduce customer churn. üéØ\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.ask(\"What can you help with? What type of dataset can you support me with?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo - Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T19:18:22.844371Z",
     "iopub.status.busy": "2025-11-30T19:18:22.844059Z",
     "iopub.status.idle": "2025-11-30T19:18:23.814661Z",
     "shell.execute_reply": "2025-11-30T19:18:23.813508Z",
     "shell.execute_reply.started": "2025-11-30T19:18:22.844348Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The overall churn rate for our bank is 20.37%. üìä That means out of 10,000 customers, 2,037 have left. We need to look into why so many customers are leaving. ‚ö†Ô∏è\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.ask(\"What's our overall churn rate?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T19:18:24.752046Z",
     "iopub.status.busy": "2025-11-30T19:18:24.751701Z",
     "iopub.status.idle": "2025-11-30T19:18:27.313269Z",
     "shell.execute_reply": "2025-11-30T19:18:27.311877Z",
     "shell.execute_reply.started": "2025-11-30T19:18:24.752019Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, here's a breakdown of our biggest churn problem based on the data:\\n\\nOur biggest churn problem is **customers in Germany**. üåç Here‚Äôs why:\\n\\n*   **Highest Churn Rate:** Germany has a churn rate of 32.00%. This is much higher compared to France (16.00%) and Spain (17.00%).\\n*   **Significant Customer Loss:** We lost 814 customers in Germany.\\n*   **High-Risk Segments:** Three out of the top five high-risk customer segments are in Germany:\\n    *   German Female Inactive: 45.00% churn\\n    *   German Male Inactive: 37.00% churn\\n    *   German Female Active: 30.00% churn\\n*   **Balance Impact:** Even though the balance lost per customer isn't specified for Germany alone, the overall balance lost from churn is significant at $185,588,094.63, and Germany contributes substantially to this.\\n\\n**Recommendation:** üéØ\\nWe need to investigate why German customers are leaving at such a high rate. We should look into regional differences in customer service, product offerings, and marketing strategies to address this specific issue. It is important to find out why customers in Germany are leaving, and what can we do to keep them.\\n\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.ask(\"What's our biggest churn problem?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T19:18:27.315065Z",
     "iopub.status.busy": "2025-11-30T19:18:27.314587Z",
     "iopub.status.idle": "2025-11-30T19:18:31.297568Z",
     "shell.execute_reply": "2025-11-30T19:18:31.296332Z",
     "shell.execute_reply.started": "2025-11-30T19:18:27.314914Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, here's a breakdown of the key factors driving customer churn at our bank, based on the data you provided:\\n\\n*   **Geography:** üåç\\n    *   Germany has a high churn rate of 32%, significantly higher than France (16%) and Spain (17%).\\n*   **Age:** üéÇ\\n    *   Customers in the 40-50 age group have a 34% churn rate.\\n    *   The 50-60 age group shows an even higher churn rate of 56%.\\n*   **Gender:** üßë\\u200dü§ù\\u200düßë\\n    *   Female customers churn at a higher rate (25%) compared to male customers (16%).\\n*   **Number of Products:** üõí\\n    *   Customers with only 1 product have a churn rate of 28%.\\n    *   Customers with 3 or 4 products have extremely high churn rates of 83% and 100% respectively, though these groups represent smaller segments of our customer base.\\n*   **Inactive Status:** üò¥\\n    *   Inactive members in Germany and other regions show very high churn rates, especially among female customers.\\n\\n**Key Insights:**\\n\\n*   German customers, particularly inactive females, are a high-risk segment.\\n*   Older customers (40-60) are more likely to churn.\\n*   Customers with a limited number of products (especially just one) are at a higher risk.\\n\\n**Recommendations:** üéØ\\n\\n*   **Targeted Retention Programs:** Develop specific programs for high-risk segments like German customers and customers in the 40-60 age range.\\n*   **Product Engagement:** Encourage customers to adopt more products, but ensure a positive experience, given the high churn among those with 3 or 4 products.\\n*   **Re-Engage Inactive Customers:** Focus on re-activating inactive customers, especially in Germany, with personalized offers and communications.\\n*   **Further Research:** Investigate *why* German customers and older demographics are churning at higher rates. This could involve surveys or focus groups.\\n\\nBy addressing these key factors, we can reduce churn and improve customer retention. üí∞\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.ask(\"Which factors contribute most to churn?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T19:18:31.299322Z",
     "iopub.status.busy": "2025-11-30T19:18:31.298935Z",
     "iopub.status.idle": "2025-11-30T19:18:33.696893Z",
     "shell.execute_reply": "2025-11-30T19:18:33.695847Z",
     "shell.execute_reply.started": "2025-11-30T19:18:31.299286Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Age has a big impact on customer churn. Here‚Äôs a breakdown üìä:\\n\\n*   **Youngest Customers (\\\\<30):** Low churn at 8.00%, or 148 out of 1968 customers.\\n*   **30-40 Age Group:** Slightly higher churn at 12.00%, with 538 out of 4451 customers leaving.\\n*   **40-50 Age Group:** Churn more than doubles to 34.00%, with 788 out of 2320 customers churning.\\n*   **50-60 Age Group:** Highest churn rate at 56.00%, where 448 out of 797 customers churn.\\n*   **Oldest Customers (60+):** Churn decreases to 25.00%, with 115 out of 464 customers.\\n\\n**Key Insight:** üåç\\n\\n*   Churn is highest for customers in the 40-60 age range, especially those in their 50s.\\n\\n**Recommendation:** üéØ\\n\\n*   Focus retention efforts on customers aged 40-60. Understand their specific needs and concerns to reduce churn. Look into what products or services might appeal to this age group to keep them as customers.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Demographics\n",
    "agent.ask(\"How does age affect churn?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T19:18:33.699160Z",
     "iopub.status.busy": "2025-11-30T19:18:33.698627Z",
     "iopub.status.idle": "2025-11-30T19:18:35.124055Z",
     "shell.execute_reply": "2025-11-30T19:18:35.123087Z",
     "shell.execute_reply.started": "2025-11-30T19:18:33.699103Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"üìä Here's the breakdown of churn by gender:\\n\\n*   **Female Churn:** 25.00% of female customers churn (1139 out of 4543).\\n*   **Male Churn:** 16.00% of male customers churn (898 out of 5457).\\n\\nüåç **Insight:** Women churn at a higher rate than men.\\n\\nüéØ **Recommendation:** Investigate why women are more likely to leave. Look into service satisfaction, product alignment, or other factors that may be driving this difference.\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.ask(\"Do men or women churn more?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T19:18:35.125840Z",
     "iopub.status.busy": "2025-11-30T19:18:35.125558Z",
     "iopub.status.idle": "2025-11-30T19:18:37.716782Z",
     "shell.execute_reply": "2025-11-30T19:18:37.715329Z",
     "shell.execute_reply.started": "2025-11-30T19:18:35.125817Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, here's the age group we should focus on to reduce churn:\\n\\n*   **Key Insight:** The highest churn rates are among customers aged 40-60. ‚ö†Ô∏è\\n\\n*   **Data Breakdown:**\\n    *   40-50 age group: 34% churn rate (788 of 2,320 customers).\\n    *   50-60 age group: 56% churn rate (448 of 797 customers).\\n    *   Comparatively, younger customers (<30 and 30-40) have much lower churn (8% and 12% respectively). üìä\\n\\n*   **Why this matters:** These two age groups (40-60) represent a large portion of our churned customers. Addressing their needs can significantly impact our overall churn rate. üë•\\n\\n*   **Recommendation:** Focus retention efforts on customers in the 40-60 age brackets. Investigate the reasons behind their high churn rates (e.g., changing life priorities, retirement planning, etc.) and tailor services/products to better meet their needs. üéØ\\n\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.ask(\"What age group should we focus on?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating User Interface for Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T19:35:06.859258Z",
     "iopub.status.busy": "2025-11-30T19:35:06.858883Z",
     "iopub.status.idle": "2025-11-30T19:35:06.889663Z",
     "shell.execute_reply": "2025-11-30T19:35:06.888255Z",
     "shell.execute_reply.started": "2025-11-30T19:35:06.859232Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Visual chatbot loaded with improved contrast!\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import google.generativeai as genai\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "class VisualChatbot:\n",
    "    \"\"\"Visual chatbot using Jupyter widgets with better contrast and visibility\"\"\"\n",
    "    \n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "        self. chat_history = []\n",
    "        self.setup_gemini()\n",
    "        self.create_ui()\n",
    "    \n",
    "    def setup_gemini(self):\n",
    "        \"\"\"Setup Gemini API\"\"\"\n",
    "        try:\n",
    "            api_key = UserSecretsClient(). get_secret(\"GOOGLE_API_KEY\")\n",
    "            genai. configure(api_key=api_key)\n",
    "            \n",
    "            model = genai.GenerativeModel(\n",
    "                model_name=\"gemini-2.0-flash-exp\",\n",
    "                generation_config={\n",
    "                    \"temperature\": 0.7,\n",
    "                    \"top_p\": 0.95,\n",
    "                    \"max_output_tokens\": 8192,\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            context = self.agent._prepare_context()\n",
    "            system_instruction = f\"\"\"You are an expert Analytics Agent specializing in bank customer churn analysis. \n",
    "\n",
    "{context}\n",
    "\n",
    "Provide clear, data-driven insights with specific numbers and actionable recommendations.\"\"\"\n",
    "            \n",
    "            self.chat_session = model.start_chat(history=[])\n",
    "            self.chat_session. send_message(system_instruction)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    def create_ui(self):\n",
    "        \"\"\"Create widget-based UI with better contrast\"\"\"\n",
    "        # Chat output area - uses flex to fill available space\n",
    "        self.chat_output = widgets.Output(\n",
    "            layout=widgets.Layout(\n",
    "                min_height='500px',\n",
    "                max_height='800px',\n",
    "                border='2px solid #667eea',\n",
    "                padding='15px',\n",
    "                overflow_y='auto',\n",
    "                background_color='#ffffff',\n",
    "                flex='1 1 auto'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Input box\n",
    "        self.input_box = widgets.Text(\n",
    "            placeholder='Type your question here...',\n",
    "            layout=widgets.Layout(width='80%'),\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Send button\n",
    "        self.send_button = widgets.Button(\n",
    "            description='Send üì§',\n",
    "            button_style='primary',\n",
    "            layout=widgets.Layout(width='18%')\n",
    "        )\n",
    "        \n",
    "        # Clear button\n",
    "        self.clear_button = widgets.Button(\n",
    "            description='Clear Chat üóëÔ∏è',\n",
    "            button_style='warning',\n",
    "            layout=widgets.Layout(width='100%', margin='10px 0')\n",
    "        )\n",
    "        \n",
    "        # Quick question buttons with full text visible\n",
    "        button_style = widgets.Layout(width='auto', min_width='200px', margin='5px')\n",
    "        self.quick_buttons = [\n",
    "            widgets.Button(description=\"üìä What's our churn rate?\", button_style='info', layout=button_style),\n",
    "            widgets.Button(description=\"‚ö†Ô∏è High-risk segments?\", button_style='info', layout=button_style),\n",
    "            widgets.Button(description=\"üí° Recommendations?\", button_style='info', layout=button_style),\n",
    "            widgets.Button(description=\"üí∞ Financial impact?\", button_style='info', layout=button_style),\n",
    "            widgets.Button(description=\"üåç Geography analysis?\", button_style='info', layout=button_style),\n",
    "            widgets.Button(description=\"üìã Executive summary?\", button_style='info', layout=button_style),\n",
    "        ]\n",
    "        \n",
    "        # Event handlers\n",
    "        self.send_button.on_click(self.on_send)\n",
    "        self.input_box.on_submit(self.on_send)\n",
    "        self.clear_button.on_click(self.on_clear)\n",
    "        \n",
    "        # Quick button handlers\n",
    "        self.quick_buttons[0].on_click(lambda b: self.send_quick_question(\"What's our overall churn rate?\"))\n",
    "        self.quick_buttons[1].on_click(lambda b: self.send_quick_question(\"Who are our high-risk customer segments?\"))\n",
    "        self.quick_buttons[2]. on_click(lambda b: self.send_quick_question(\"What are your top recommendations to reduce churn?\"))\n",
    "        self.quick_buttons[3].on_click(lambda b: self.send_quick_question(\"What's the financial impact of churn?\"))\n",
    "        self.quick_buttons[4].on_click(lambda b: self. send_quick_question(\"Which geography has the highest churn?\"))\n",
    "        self.quick_buttons[5].on_click(lambda b: self.send_quick_question(\"Give me an executive summary\"))\n",
    "        \n",
    "        # Display welcome message\n",
    "        with self.chat_output:\n",
    "            display(HTML(\"\"\"\n",
    "            <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 25px; border-radius: 10px; text-align: center; margin-bottom: 20px;\">\n",
    "                <h2 style=\"margin: 0; color: white;\">ü§ñ Bank Customer Churn Analytics Agent</h2>\n",
    "                <p style=\"margin: 10px 0; color: white; font-size: 16px;\">Powered by Google Gemini AI</p>\n",
    "                <p style=\"font-size: 14px; opacity: 0.95; color: white;\">Ask me anything about customer churn patterns and recommendations! </p>\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the chat interface\"\"\"\n",
    "        # Header with better styling\n",
    "        header = widgets.HTML(\"\"\"\n",
    "        <div style=\"margin-bottom: 15px; padding: 10px; background: #f8f9fa; border-radius: 8px; border-left: 4px solid #667eea;\">\n",
    "            <h3 style=\"margin: 0; color: #333;\">üí° Quick Questions (Click to Ask):</h3>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        \n",
    "        # Layout quick buttons in rows with better spacing\n",
    "        quick_buttons_row1 = widgets.HBox([self.quick_buttons[0], self.quick_buttons[1], self.quick_buttons[2]], \n",
    "                                          layout=widgets.Layout(justify_content='flex-start', margin='5px 0'))\n",
    "        quick_buttons_row2 = widgets.HBox([self.quick_buttons[3], self.quick_buttons[4], self.quick_buttons[5]], \n",
    "                                          layout=widgets.Layout(justify_content='flex-start', margin='5px 0'))\n",
    "        \n",
    "        quick_buttons_box = widgets.VBox([quick_buttons_row1, quick_buttons_row2])\n",
    "        \n",
    "        # Chat label\n",
    "        chat_label = widgets.HTML(\"\"\"\n",
    "        <div style='margin: 20px 0 10px 0; padding: 10px; background: #f8f9fa; border-radius: 8px; border-left: 4px solid #667eea;'>\n",
    "            <strong style=\"color: #333;\">üí¨ Chat:</strong>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        \n",
    "        # Chat area wrapper - allows chat to expand and scroll\n",
    "        chat_area = widgets.VBox(\n",
    "            [chat_label, self.chat_output],\n",
    "            layout=widgets.Layout(flex='1 1 auto', min_height='350px')\n",
    "        )\n",
    "        \n",
    "        # Input section - fixed at bottom\n",
    "        input_section = widgets.VBox(\n",
    "            [\n",
    "                widgets.HBox(\n",
    "                    [self.input_box, self.send_button],\n",
    "                    layout=widgets.Layout(width='100%', margin='10px 0 0 0')\n",
    "                ),\n",
    "                self.clear_button\n",
    "            ],\n",
    "            layout=widgets.Layout(flex='0 0 auto')\n",
    "        )\n",
    "        \n",
    "        # Complete UI with flex layout\n",
    "        ui = widgets.VBox(\n",
    "            [\n",
    "                header,\n",
    "                quick_buttons_box,\n",
    "                chat_area,\n",
    "                input_section\n",
    "            ],\n",
    "            layout=widgets.Layout(\n",
    "                display='flex',\n",
    "                flex_flow='column',\n",
    "                height='900px'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        display(ui)\n",
    "    \n",
    "    def on_send(self, b):\n",
    "        \"\"\"Handle send button click\"\"\"\n",
    "        message = self. input_box.value. strip()\n",
    "        if message:\n",
    "            self.send_message(message)\n",
    "            self.input_box.value = ''\n",
    "    \n",
    "    def send_quick_question(self, question):\n",
    "        \"\"\"Send a quick question\"\"\"\n",
    "        self.send_message(question)\n",
    "    \n",
    "    def send_message(self, message):\n",
    "        \"\"\"Send message and display response with better contrast\"\"\"\n",
    "        # Display user message with dark text\n",
    "        with self.chat_output:\n",
    "            display(HTML(f\"\"\"\n",
    "            <div style=\"background: #e3f2fd; padding: 15px; border-radius: 10px; margin: 10px 0; border-left: 4px solid #2196f3; box-shadow: 0 2px 4px rgba(0,0,0,0.1);\">\n",
    "                <strong style=\"color: #1565c0; font-size: 14px;\">üíº You:</strong>\n",
    "                <p style=\"margin: 8px 0 0 0; color: #212121; font-size: 14px; line-height: 1.6;\">{message}</p>\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "        \n",
    "        # Show thinking indicator\n",
    "        with self.chat_output:\n",
    "            display(HTML(\"\"\"\n",
    "            <div style=\"background: #fff9c4; padding: 10px; border-radius: 8px; margin: 10px 0; text-align: center;\">\n",
    "                <span style=\"color: #f57c00;\">ü§ñ Agent is thinking...</span>\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "        \n",
    "        # Get response\n",
    "        try:\n",
    "            response = self.chat_session.send_message(message)\n",
    "            response_text = response. text\n",
    "            \n",
    "            # Clear thinking indicator and display agent response with dark text\n",
    "            self.chat_output.clear_output(wait=True)\n",
    "            \n",
    "            # Re-display all chat history\n",
    "            for item in self.chat_history:\n",
    "                with self.chat_output:\n",
    "                    display(HTML(f\"\"\"\n",
    "                    <div style=\"background: #e3f2fd; padding: 15px; border-radius: 10px; margin: 10px 0; border-left: 4px solid #2196f3; box-shadow: 0 2px 4px rgba(0,0,0,0.1);\">\n",
    "                        <strong style=\"color: #1565c0; font-size: 14px;\">üíº You:</strong>\n",
    "                        <p style=\"margin: 8px 0 0 0; color: #212121; font-size: 14px; line-height: 1.6;\">{item['user']}</p>\n",
    "                    </div>\n",
    "                    \"\"\"))\n",
    "                    \n",
    "                    # Convert markdown-style formatting to HTML\n",
    "                    formatted_response = item['agent']. replace('\\n', '<br>')\n",
    "                    formatted_response = formatted_response.replace('**', '<strong>').replace('**', '</strong>')\n",
    "                    \n",
    "                    display(HTML(f\"\"\"\n",
    "                    <div style=\"background: #f5f5f5; padding: 15px; border-radius: 10px; margin: 10px 0; border-left: 4px solid #667eea; box-shadow: 0 2px 4px rgba(0,0,0,0.1);\">\n",
    "                        <strong style=\"color: #5e35b1; font-size: 14px;\">ü§ñ Agent:</strong>\n",
    "                        <div style=\"margin: 8px 0 0 0; color: #212121; font-size: 14px; line-height: 1. 8;\">{formatted_response}</div>\n",
    "                    </div>\n",
    "                    \"\"\"))\n",
    "            \n",
    "            # Display current message and response\n",
    "            with self.chat_output:\n",
    "                display(HTML(f\"\"\"\n",
    "                <div style=\"background: #e3f2fd; padding: 15px; border-radius: 10px; margin: 10px 0; border-left: 4px solid #2196f3; box-shadow: 0 2px 4px rgba(0,0,0,0.1);\">\n",
    "                    <strong style=\"color: #1565c0; font-size: 14px;\">üíº You:</strong>\n",
    "                    <p style=\"margin: 8px 0 0 0; color: #212121; font-size: 14px; line-height: 1.6;\">{message}</p>\n",
    "                </div>\n",
    "                \"\"\"))\n",
    "                \n",
    "                # Convert markdown-style formatting to HTML\n",
    "                formatted_response = response_text.replace('\\n', '<br>')\n",
    "                formatted_response = formatted_response.replace('**', '<strong>').replace('**', '</strong>')\n",
    "                \n",
    "                display(HTML(f\"\"\"\n",
    "                <div style=\"background: #f5f5f5; padding: 15px; border-radius: 10px; margin: 10px 0; border-left: 4px solid #667eea; box-shadow: 0 2px 4px rgba(0,0,0,0.1);\">\n",
    "                    <strong style=\"color: #5e35b1; font-size: 14px;\">ü§ñ Agent:</strong>\n",
    "                    <div style=\"margin: 8px 0 0 0; color: #212121; font-size: 14px; line-height: 1.8;\">{formatted_response}</div>\n",
    "                </div>\n",
    "                \"\"\"))\n",
    "            \n",
    "            # Store in history\n",
    "            self.chat_history.append({\"user\": message, \"agent\": response_text})\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Clear thinking indicator\n",
    "            self.chat_output.clear_output(wait=True)\n",
    "            \n",
    "            # Re-display chat history\n",
    "            for item in self. chat_history:\n",
    "                with self.chat_output:\n",
    "                    display(HTML(f\"\"\"\n",
    "                    <div style=\"background: #e3f2fd; padding: 15px; border-radius: 10px; margin: 10px 0; border-left: 4px solid #2196f3;\">\n",
    "                        <strong style=\"color: #1565c0;\">üíº You:</strong>\n",
    "                        <p style=\"margin: 8px 0 0 0; color: #212121;\">{item['user']}</p>\n",
    "                    </div>\n",
    "                    <div style=\"background: #f5f5f5; padding: 15px; border-radius: 10px; margin: 10px 0; border-left: 4px solid #667eea;\">\n",
    "                        <strong style=\"color: #5e35b1;\">ü§ñ Agent:</strong>\n",
    "                        <div style=\"margin: 8px 0 0 0; color: #212121;\">{item['agent']}</div>\n",
    "                    </div>\n",
    "                    \"\"\"))\n",
    "            \n",
    "            # Display error\n",
    "            with self.chat_output:\n",
    "                display(HTML(f\"\"\"\n",
    "                <div style=\"background: #ffebee; padding: 15px; border-radius: 10px; margin: 10px 0; border-left: 4px solid #f44336; box-shadow: 0 2px 4px rgba(0,0,0,0.1);\">\n",
    "                    <strong style=\"color: #c62828; font-size: 14px;\">‚ùå Error:</strong>\n",
    "                    <p style=\"margin: 8px 0 0 0; color: #212121; font-size: 14px;\">{str(e)}</p>\n",
    "                </div>\n",
    "                \"\"\"))\n",
    "    \n",
    "    def on_clear(self, b):\n",
    "        \"\"\"Clear chat history\"\"\"\n",
    "        self.chat_output.clear_output()\n",
    "        self.chat_history = []\n",
    "        with self.chat_output:\n",
    "            display(HTML(\"\"\"\n",
    "            <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 25px; border-radius: 10px; text-align: center; margin-bottom: 20px;\">\n",
    "                <h2 style=\"margin: 0; color: white;\">ü§ñ Bank Customer Churn Analytics Agent</h2>\n",
    "                <p style=\"margin: 10px 0; color: white; font-size: 16px;\">Powered by Google Gemini AI</p>\n",
    "                <p style=\"font-size: 14px; opacity: 0.95; color: white;\">Ask me anything about customer churn patterns and recommendations!</p>\n",
    "            </div>\n",
    "            <div style=\"background: #e8f5e9; padding: 15px; border-radius: 8px; text-align: center; border: 2px solid #4caf50;\">\n",
    "                <span style=\"color: #2e7d32; font-size: 16px; font-weight: bold;\">‚úÖ Chat cleared!  Ask me anything about customer churn. </span>\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "\n",
    "# Create visual chatbot\n",
    "def create_visual_chatbot(agent):\n",
    "    \"\"\"Create and display visual chatbot\"\"\"\n",
    "    chatbot = VisualChatbot(agent)\n",
    "    chatbot.display()\n",
    "    return chatbot\n",
    "\n",
    "print(\"‚úÖ Visual chatbot loaded with improved contrast!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T19:35:11.136297Z",
     "iopub.status.busy": "2025-11-30T19:35:11.135887Z",
     "iopub.status.idle": "2025-11-30T19:35:21.612956Z",
     "shell.execute_reply": "2025-11-30T19:35:21.610639Z",
     "shell.execute_reply.started": "2025-11-30T19:35:11.136267Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47/1042012250.py:92: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  self.input_box.on_submit(self.on_send)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433de0257717496f84f2fffeb5926a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n        <div style=\"margin-bottom: 15px; padding: 10px; background: #f8f9fa; bord‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and display the improved chatbot\n",
    "visual_chatbot = create_visual_chatbot(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-30T19:07:01.296721Z",
     "iopub.status.idle": "2025-11-30T19:07:01.297025Z",
     "shell.execute_reply": "2025-11-30T19:07:01.296912Z",
     "shell.execute_reply.started": "2025-11-30T19:07:01.296900Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Geographic Analysis\n",
    "# agent.ask(\"Which countries have the highest churn? \")\n",
    "# agent.ask(\"Why is Germany churning more than other countries?\")\n",
    "\n",
    "# # Product & Engagement\n",
    "# agent.ask(\"How do product holdings affect churn?\")\n",
    "# agent. ask(\"What about active vs inactive members?\")\n",
    "\n",
    "# # Risk & Segments\n",
    "# agent.ask(\"Who are our highest-risk customers?\")\n",
    "# agent.ask(\"What customer segments should we prioritize?\")\n",
    "\n",
    "# # Financial Impact\n",
    "# agent.ask(\"What's the financial impact of churn?\")\n",
    "# agent.ask(\"How much revenue are we losing? \")\n",
    "# agent.ask(\"If we reduce churn by 15%, what's the savings?\")\n",
    "\n",
    "# # Recommendations\n",
    "# agent.ask(\"What should we do to reduce churn?\")\n",
    "# agent.ask(\"Give me your top 5 action items\")\n",
    "# agent.ask(\"What's our best retention strategy?\")\n",
    "\n",
    "# # Complex Questions\n",
    "# agent.ask(\"Compare Germany vs France churn patterns\")\n",
    "# agent.ask(\"Why do customers with more products churn more?\")\n",
    "# agent.ask(\"What's the profile of a typical churned customer?\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4649694,
     "sourceId": 8433834,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
